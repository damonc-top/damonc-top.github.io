[ { "title": "Git Worktree并行开发：原理、实践与最佳实践", "url": "/posts/git-worktree-parallel-development/", "categories": "Git, 开发工具", "tags": "git-worktree, 并行开发, 版本控制, 工作流优化", "date": "2026-01-22 23:30:00 +0800", "content": "Git Worktree是现代Git工作流中的重要工具，为并行开发提供了轻量级解决方案 Git Worktree工作原理 Git Worktree是Git 2.5+版本引入的功能，允许在同一个Git仓库中创建多个工作目录。其核心设计理念基于共享对象数据库和独立工作环境的巧妙结合。 架构演进 传统Git工作流中，每个仓库只有一个工作目录，而Worktree打破了这一限制，实现了”一个仓库，多个工作环境”的架构： graph TB subgraph \"传统Git架构\" A[主仓库] --&gt; B[工作目录] A --&gt; C[对象数据库] A --&gt; D[引用数据库] end subgraph \"Git Worktree架构\" E[主仓库] --&gt; F[对象数据库] E --&gt; G[引用数据库] E --&gt; H[工作树管理] H --&gt; I[工作树1] H --&gt; J[工作树2] H --&gt; K[工作树3] I --&gt; L[工作目录1] J --&gt; M[工作目录2] K --&gt; N[工作目录3] end 完整工作流程 下图展示了Git Worktree的完整工作流程： 图：Git Worktree完整工作流程示意图 环境变量机制 基本架构 graph TD A[主Git仓库] --&gt; B[对象数据库 objects/] A --&gt; C[打包引用 packed-refs] A --&gt; D[共享配置] A --&gt; E[工作树管理目录 .git/worktrees/] E --&gt; F[工作树A HEAD, index, gitdir] E --&gt; G[工作树B HEAD, index, gitdir] F --&gt; H[链接工作目录A] G --&gt; I[链接工作目录B] H --&gt; J[工作文件A] I --&gt; K[工作文件B] 环境变量机制 每个工作树通过环境变量管理路径解析： GIT_DIR: 指向工作树特定的管理目录 GIT_COMMON_DIR: 指向共享的主仓库目录 工作目录空间占用原理 共享内容（零额外开销） 对象数据库 (objects/ 目录) - 所有commit、tree、blob对象 打包引用 (packed-refs) - 压缩的引用信息 配置共享部分 - 全局Git配置 钩子脚本 (hooks/) - Git事件处理脚本 独立内容（最小开销） 索引文件 (index) - 每个工作树独有的暂存区状态 HEAD引用 - 当前工作树指向的commit 工作树特定引用 - 如 refs/worktree/, refs/bisect/ 工作树配置 - 当启用 extensions.worktreeConfig 时 空间节省示例 # 主仓库大小 du -sh .git # 例如: 50MB # 每个额外工作树增加的大小 du -sh .git/worktrees/* # 通常只有几KB到几十KB 性能对比分析 特性 Git Worktree 传统 git clone 优势 存储占用 ~50MB + 微量 50MB × N 节省 90%+空间 时间成本 即时创建 整个仓库克隆 节省 95%+时间 网络带宽 无需网络 整个历史下载 节省 99%+带宽 数据一致性 完全一致 需要手动同步 自动同步 并行能力 真正并行 分离环境 无等待时间 实际应用效果 graph LR A[传统方式] --&gt; B[大型项目: 2GB] B --&gt; C[创建3个工作环境] C --&gt; D[总占用: 6GB] C --&gt; E[时间: 10分钟] C --&gt; F[网络: 6GB下载] G[使用Worktree] --&gt; H[大型项目: 2GB] H --&gt; I[创建3个工作树] I --&gt; J[总占用: 2GB + 300KB] I --&gt; K[时间: 3秒钟] I --&gt; L[网络: 0KB] 对于大型项目，Git Worktree可以节省数GB的存储空间和数十分钟的网络下载时间 冲突避免与锁机制 引用隔离机制 # 共享引用（所有工作树可见） refs/heads/* # 分支引用 refs/tags/* # 标签引用 # 工作树特定引用（各自独立） refs/bisect/* # 二分查找状态 refs/worktree/* # 工作树特定状态 refs/rewritten/* # 变基操作状态 文件锁机制 Git通过多种锁机制确保操作安全： 索引锁 - 防止多个进程同时修改暂存区 引用锁 - 保护引用更新操作 工作树锁 - git worktree lock 手动锁定 修改同一文件的场景 当两个工作树修改同一文件时，Git通过以下机制避免冲突： sequenceDiagram participant DevA as 开发者A participant WT_A as 工作树A participant Index_A as 索引A participant Repo as 共享仓库 participant Index_B as 索引B participant WT_B as 工作树B participant DevB as 开发者B Note over DevA, DevB: 并行修改文件file.txt DevA-&gt;&gt;WT_A: vim file.txt (修改内容) DevB-&gt;&gt;WT_B: vim file.txt (修改内容) DevA-&gt;&gt;Index_A: git add file.txt DevB-&gt;&gt;Index_B: git add file.txt DevA-&gt;&gt;Repo: git commit -m \"修改A\" DevB-&gt;&gt;Repo: git commit -m \"修改B\" Note over Repo: 两个提交存在于不同分支 DevA-&gt;&gt;Repo: git merge 工作树B的提交 Repo--&gt;&gt;DevA: 检测到冲突 DevA-&gt;&gt;DevA: 解决冲突 DevA-&gt;&gt;Repo: git commit -m \"解决冲突\" 冲突避免机制详解 文件副本独立性：每个工作树有自己的文件副本 索引隔离：每个工作树的索引独立运作 引用分离：分支引用共享，但工作树特定引用独立 合并时检测：只有在合并操作时才会检测冲突 由于每个工作树有独立的索引和工作目录，修改的是各自的文件副本，只有在推送或合并时才会遇到冲突 与vib-kanban项目的相似性 虽然具体实现不同，但设计理念相似： 并行工作流支持 特性 Git Worktree vib-kanban 多任务处理 多个分支同时开发 多列任务并行处理 上下文隔离 独立工作目录 独立任务卡片 资源复用 共享对象数据库 可能共享状态管理 管理界面相似性 都需要列表显示所有工作环境/任务 提供创建、删除、切换等操作 支持状态跟踪和进度管理 实际操作指南 基本操作命令 # 创建新工作树 git worktree add ../new-feature feature-branch # 列出所有工作树 git worktree list # 移动到特定工作树 cd ../new-feature # 删除工作树 git worktree remove ../new-feature # 清理过期工作树 git worktree prune 实际应用场景 场景1：紧急热修复 # 在主分支开发时发现紧急bug git worktree add ../hotfix master git -C ../hotfix checkout -b hotfix/urgent # 在hotfix目录中修复并测试 cd ../hotfix vim fix.js git add . git commit -m \"紧急修复\" git push origin hotfix/urgent 场景2：功能并行开发 # 同时开发两个功能 git worktree add ../feature-a feature/a git worktree add ../feature-b feature/b # 在不同终端中并行工作 # 终端1: cd ../feature-a &amp;&amp; npm run dev # 终端2: cd ../feature-b &amp;&amp; npm run dev 场景3：代码审查 # 审查PR时创建独立环境 git worktree add ../pr-review pr-branch cd ../pr-review npm install npm test # 在隔离环境中测试 高级配置 启用工作树特定配置： git config extensions.worktreeConfig true # 设置工作树特定配置 git config --worktree user.email \"worktree@example.com\" git config --worktree core.editor \"code --wait\" 企业级应用场景 大型团队开发流程 graph TD A[主开发分支] --&gt; B[快速修复环境] A --&gt; C[功能开发环境] A --&gt; D[测试验证环境] A --&gt; E[代码审查环境] B --&gt; F[热修工作树] C --&gt; G[功能工作树] D --&gt; H[测试工作树] E --&gt; I[审查工作树] F --&gt; J[立即部署测试] G --&gt; K[并行开发测试] H --&gt; L[独立测试环境] I --&gt; M[原始代码审查] 微服务架构下的应用 场景1：多服务并行开发 # 为每个微服务创建独立开发环境 git worktree add ../user-service feature/user-auth git worktree add ../order-service feature/order-process git worktree add ../payment-service feature/payment-gateway # 并行启动所有服务 cd ../user-service &amp;&amp; npm run dev &amp; cd ../order-service &amp;&amp; npm run dev &amp; cd ../payment-service &amp;&amp; npm run dev &amp; 场景2：多环境测试 # 创建不同测试环境 git worktree add ../test-staging staging git worktree add ../test-production production # 同时运行多环境测试 cd ../test-staging &amp;&amp; npm test cd ../test-production &amp;&amp; npm test 连续集成/连续部署(CI/CD) sequenceDiagram participant Dev as 开发者 participant WT as Worktree participant CI as CI/CD服务器 participant Prod as 生产环境 Dev-&gt;&gt;WT: git worktree add ../ci-test Dev-&gt;&gt;WT: 在测试环境测试 Dev-&gt;&gt;CI: 推送到CI服务器 CI-&gt;&gt;CI: 自动创建测试Worktree CI-&gt;&gt;CI: 执行自动化测试 CI-&gt;&gt;Prod: 部署到生产环境 最佳实践与注意事项 企业级推荐实践 统一命名规范：&lt;team&gt;-&lt;project&gt;-&lt;purpose&gt; 自动化管理：通过脚本管理工作树生命周期 监控告警：设置工作树超时和资源监控 文档化：维护工作树使用文档和流程图 高级配置建议 # 启用工作树特定配置 git config extensions.worktreeConfig true # 设置团队级别配置 git config --worktree user.name \"Team Developer\" git config --worktree user.email \"team@company.com\" git config --worktree core.editor \"code --wait\" # 自动化清理脚本 # 添加到.git/hooks/post-commit #!/bin/sh git worktree prune --expire=30.days 注意事项 避免在工作树中使用子模块，官方文档标注此功能为实验性 在企业环境中，建议配合Docker容器使用，实现更好的环境隔离 故障排除与恢复 工作树连接断开时： # 手动修复连接 git worktree repair # 或重新链接 echo \"gitdir: /path/to/main/.git/worktrees/worktree-name\" &gt; .git # 快速重建工作树 git worktree remove ../broken-tree git worktree add ../new-tree branch-name 未来发展趋势 智能化发展 未来Git Worktree可能集成更多智能功能： graph TB A[智能Worktree] --&gt; B[自动分配资源] A --&gt; C[动态扩缩容] A --&gt; D[预觨发冲突] A --&gt; E[自动优化缓存] B --&gt; F[根据项目需求分配CPU/内存] C --&gt; G[根据工作负荷自动扩缩容] D --&gt; H[预测并避免潜在冲突] E --&gt; I[自动管理缓存提高性能] 云原生支持 与云平台深度集成，实现： 云端工作树同步 分布式缓存共享 跨区域并行开发 AI助理自动优化 总结 Git Worktree通过巧妙的文件链接和路径重定向机制，在保持Git强大功能的同时，提供了轻量级的并行开发解决方案。它： ✅ 显著减少存储空间占用（90%+节省） ✅ 提供真正的并行开发能力（无等待时间） ✅ 避免上下文切换的开销（保持开发流畅） ✅ 保持操作的安全性和隔离性（内置锁机制） ✅ 支持企业级应用（微服务、CI/CD集成） ✅ 提供丰富可视化展示（SVG+Mermaid） 案例效果展示 pie title Git Worktree效果对比 \"节省存储空间\" : 90 \"节省网络带宽\" : 99 \"节省时间成本\" : 95 \"提升开发效率\" : 80 对于需要同时处理多个分支、进行代码审查或紧急修复的开发场景，Git Worktree是一个不可或缺的工具。随着云原生技术的发展，它还将集成更多智能化功能，为开发者提供更高效、更便捷的并行开发体验。 本文基于实际项目经验和技术分析撰写，包含丰富的可视化图表和实际案例，希望对您的开发工作有所帮助。" }, { "title": "Claude Code(十)思考与技巧：克服\"空白瘫痪\"，不断向前演进", "url": "/posts/claude-code-tips_tricks/", "categories": "AI, Claude Code", "tags": "AI, CLI Agent, Best Practices", "date": "2026-01-22 20:31:00 +0800", "content": "这是 Claude Code 系列文章的最后一篇。 经过前面九章的学习，我已经掌握了从环境配置到 MCP 协议的所有硬核技能。但在每天高强度的使用中，我发现要把工具用好，“心法”往往比”招式”更重要。 本文记录了我在与 Claude Code 结对编程数月后，沉淀下来的一些思考和实用技巧。 克服”空白瘫痪” (Blank Canvas Paralysis) 我刚开始使用 Agent 时，经常盯着闪烁的光标发呆：我该怎么描述这个复杂的重构任务？我是不是应该先写一个 500 字的完美 Prompt？ 这种犹豫被称为”空白瘫痪”。 我的对策：Just Start (先开始再说)。 Claude Code 不是一次性交付的黑盒，它是交互式的。我现在的习惯是： “嘿，先帮我看看 src/auth 目录下的代码，我感觉逻辑有点乱。” 哪怕只是这样一个模糊的指令，Claude 也会开始运行 ls 和 read_file。随着它的反馈（”我看到了 user.ts 和 auth.ts…“），我的思路会被打开，然后我再进行第二轮指令： “对，就是 auth.ts，里面的 login 函数有点太长了，帮我拆分一下。” 技巧：不要试图一次性把话说完。把对话当成是和同事在白板前的讨论，从模糊到清晰，迭代前进。 小步快跑与频繁提交 AI 是有短期记忆瓶颈的（Context Window）。如果我让它一口气”重构整个后端”，它很可能会在修改了 50 个文件后，因为 Token 超标而崩溃，或者改到最后忘了最初的目标。 我的对策：原子化提交 (Atomic Commits)。 我现在的 workflow 是这样的： Task 1: “给 User 增加 phone 字段。” -&gt; Claude 做完 -&gt; 我 /review -&gt; git commit。 Task 2: “更新相关的 API 验证逻辑。” -&gt; Claude 做完 -&gt; 我 /review -&gt; git commit。 Task 3: “补充单元测试。” -&gt; Claude 做完 -&gt; 我 /review -&gt; git commit。 每一步都保持上下文清爽。如果某一步搞砸了，我也能轻松 /rewind 或 git reset，而不会损失整个下午的工作。 从”纠正”到”教学” 这是新手和高手的最大区别。 当 Claude 犯错时（比如它又用了 console.log 而不是 logger），新手会说： “错了，改成 logger。” Claude 会改过来，但下一次它可能还会犯。 高手会说： “错了。请更新 CLAUDE.md，添加一条规则：’前端项目严禁使用 console.log，必须统一使用 src/utils/logger‘。然后帮我修正代码。” 我的对策：知识沉淀。 我把每一次错误都视为一次完善系统记忆（System Memory）的机会。随着 CLAUDE.md 的不断丰富，我的 Agent 会越来越懂我，错误率呈指数级下降。 善用 /compact 保持大脑清醒 当会话进行到 30 轮以上时，我能明显感觉到 Claude 变”笨”了。它开始忽略我的新指令，或者在旧代码上打转。 这是因为无关的上下文噪音（Noise）太多了。 我的对策：主动垃圾回收 (GC)。 一旦我完成了一个阶段性的小任务（比如修好了一个 Bug），我会立刻执行： /compact \"刚刚修复了登录 Bug，现在准备开始优化注册流程。\" 这相当于给 Claude 洗了个脸，让它清空短期记忆，只保留核心的项目状态，轻装上阵迎接下一个任务。 结语：人机共生的未来 写完这个系列，我最大的感触是：Claude Code 并没有取代我，它增强了我。 以前，我 70% 的时间在写样板代码、查文档、调试低级错误，只有 30% 的时间在思考架构和业务。 现在，这个比例倒过来了。我变成了架构师、Code Reviewer 和产品经理。 我不再是那个在那敲键盘的”码农”，我是指挥硅基大脑构建数字大厦的”工程师”。 希望这个系列能帮助你（哦不，是帮助未来的我）在这个 AI 辅助编程的新时代，找到属于自己的节奏。 Keep Coding, Keep Evolving." }, { "title": "Claude Code(九)Plugins：扩展功能的无限可能", "url": "/posts/claude-code-plugins/", "categories": "AI, Claude Code", "tags": "AI, CLI Agent, Plugins", "date": "2026-01-21 21:30:10 +0800", "content": "在构建了坚实的配置基础（Config）、强大的技能（Skills）和连接万物的协议（MCP）之后，我发现 Claude Code 的生态拼图还差最后一块——Plugins（插件）。 如果把 Claude Code 比作 Chrome 浏览器，MCP 是底层的 HTTP 协议，Subagents 是不同的网页标签，那么 Plugins 就是那些让我们爱不释手的 Chrome 扩展程序。 本文记录了我对 Claude Code 插件系统的探索，以及它如何填补了功能的最后”一公里”。 Core Principles：插件的定位 在使用过程中，我经常被问到一个问题：“Plugins 和 MCP 到底有什么区别？” 经过实战，我总结了以下对比： 特性 MCP Server Plugins 核心隐喻 数据线 (USB Cable) 功能包 (Extension) 侧重点 连接外部数据（如 DB、GitHub） 增强核心能力（如绘图、搜索） 运行位置 独立进程，可能在远程 注入在 Claude Code 运行时内部 典型例子 postgres-server (连接数据库) mermaid-renderer (渲染流程图) 简单来说，如果我想让 Claude “看到” 更多东西，我用 MCP；如果我想让 Claude “做” 更多事情，我用 Plugins。 Practical Implementation：插件管理 Claude Code 提供了一套类似 npm 或 brew 的包管理体验。 发现与安装 我可以使用 /plugins 命令来管理插件： # 列出已安装插件 /plugins list # 搜索市场中的插件 /plugins search search-web # 安装插件 /plugins install @anthropic/web-search 实战案例：Web Search 插件 在我安装了 @anthropic/web-search 插件后，Claude 瞬间拥有了联网能力。这与 MCP 的 brave-search 类似，但 Plugin 通常封装得更深，体验更丝滑。 “Claude, 帮我查一下 React 19 最新的 Hook 变更，并总结对我们项目的影响。” 它会自动调用插件提供的 search 工具，阅读多篇最新的技术博客，然后结合我当前的项目代码（Context），给出一份针对性的迁移报告。 实战案例：Code Interpreter (代码解释器) 这是我最依赖的一个官方插件。虽然 Claude Code 原生能写代码，但它默认是在我的终端里运行。 安装 code-interpreter 插件后，Claude 获得了一个隔离的 Python 沙箱。 “分析这个 CSV 文件的数据分布，画一张热力图。” Claude 会在沙箱中运行 Python 代码，生成 Matplotlib 图表，并直接在终端或 IDE 中展示给我。这完全不污染我的本地环境，非常适合做数据分析和原型验证。 Deep Analysis：插件的解剖学 在深入研究了官方的 code-review、hookify 和 plugin-dev 等插件源码后，我发现一个 Claude Code 插件的结构远比我想象的要严谨。它不仅仅是一堆 Prompt 的集合，而是一个标准的工程项目。 核心目录结构 一个典型的生产级插件遵循特定的物理布局，这决定了 Claude Code 如何加载和识别各个组件： my-plugin/ ├── .claude-plugin/ │ └── plugin.json # 插件的\"身份证\"，定义元数据 ├── commands/ # 快捷命令 (Slash Commands)，如 /code-review │ └── review.md # 每个 Markdown 文件定义一个命令 ├── agents/ # 专用子智能体 (Sub-agents) │ └── bug-hunter.md # 复杂任务的编排逻辑 ├── skills/ # Agent 技能 (Skills) │ └── my-skill/ │ └── SKILL.md # 核心说明文档，定义工具使用逻辑 ├── hooks/ # 事件钩子 (Hooks) │ └── hooks.json # 钩子触发定义 └── scripts/ # 辅助脚本 (Bash/Python/JS) 关键约束：千万不要把 commands/、agents/ 等目录放进 .claude-plugin/ 文件夹内部，它们必须位于插件根目录。 Manifest 定义 (plugin.json) plugin.json 是插件的入口，它除了定义名称和版本，最重要的作用是权限声明和命名空间定义： { \"name\": \"my-first-plugin\", \"description\": \"A professional toolset for AI-assisted dev\", \"version\": \"1.0.0\", \"permissions\": [\"bash\", \"gh\", \"read\", \"write\"], // 显式声明工具访问权限 \"author\": { \"name\": \"Damon\", \"email\": \"damon@example.com\" } } 通过 name 字段，插件的所有命令会自动获得命名空间保护（如 /my-first-plugin:hello），这有效避免了不同插件之间的命令冲突。 事件钩子 (Hooks)：干预生命周期 Hooks 是插件系统中最具”侵入性”但也最强大的特性。通过 hooks/hooks.json，插件可以监听并干预 Claude Code 的核心操作流： PreToolUse: 在工具（如 Bash, Write）执行前运行。常用于安全审计或自动注入参数。 PostToolUse: 工具执行后运行。常用于自动格式化代码或运行测试。 UserPromptSubmit: 在用户提交问题时运行。可以拦截用户输入并注入特定的上下文（如项目的架构图）。 Stop: 任务完成时触发。用于最终的质量把关。 { \"hooks\": { \"PostToolUse\": [ { \"matcher\": \"Write|Edit\", \"hooks\": [{ \"type\": \"command\", \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/scripts/validate.py\", \"timeout\": 10 }] } ] } } ${CLAUDE_PLUGIN_ROOT} 环境变量的存在，使得插件内的脚本调用能够保持路径独立，这对于分发和共享至关重要。 Advanced Implementation：剖析官方 Code Review 插件 Anthropic 官方提供的 code-review 插件是智能体编排（Agent Orchestration）的最佳实践。 成本与效率的权衡 (Tiered Processing) 当你输入 /code-review 时，它采用的是分层处理策略： Haiku Gatekeeper: 首先启动快速的 Haiku 模型进行初步检查。如果是 Draft PR 或极其琐碎的修改（如拼写错误），流程直接终止。 Context Gathering: 它会扫描项目中的 CLAUDE.md，不仅是根目录的，还包括被修改文件所在子目录的特定规范。 并行协同流水线 (Parallel Sub-agents) 插件会同时启动 4 个 Agent 并行工作，这在 Claude Code 中通过 Task 接口实现： Worker 1 &amp; 2 (Sonnet): 拿着 CLAUDE.md 逐行审计合规性。 Worker 3 (Opus): 专注于 Bug 扫描。它被告知”只看 Diff，不看上下文”，以保持对逻辑错误的极致敏感度。 Worker 4 (Opus): 专注于安全与逻辑一致性。 置信度过滤与二次验证 (Validation Loop) 这是最严谨的一步：对于 Worker 发现的每一个 Issue，插件会启动独立的验证子智能体。 验证者会拿到 PR 的描述和 Issue 详情，确认”这真的算个 Bug 吗？” 只有通过二次验证且置信度 ≥ 80 的问题，才会最终通过 GitHub CLI (gh) 提交为 Inline Comment。 实战案例：从 Standalone 迁移到 Plugin 如果你已经在 .claude/ 下积累了很多好用的配置，迁移到插件模式只需三步： 物理隔离：创建新文件夹，建立 .claude-plugin/plugin.json。 文件对齐： .claude/commands/ -&gt; my-plugin/commands/ .claude/agents/ -&gt; my-plugin/agents/ .claude/skills/ -&gt; my-plugin/skills/ 配置解耦：将 settings.json 中的 hooks 配置提取到 my-plugin/hooks/hooks.json。 生态精选：Marketplace Highlights 在官方的 marketplace.json 中，有几个插件展示了插件系统的不同边界： hookify: 展示了如何通过插件提供一个”配置框架”，允许用户通过简单的 Markdown 定义钩子。 pr-review-toolkit: 提供了更细粒度的 PR 审查，包含 silent-failure-hunter 和 type-design-analyzer 等专项 Agent。 plugin-dev: 包含了大量的开发辅助 Skill，甚至包括 plugin-validator 和 skill-reviewer。 结语 Plugins 将 Claude Code 从一个单纯的 “对话式 AI” 升华为一个 “可插拔的研发操作系统”。通过 Manifest 权限边界、Hooks 生命周期干预 和 Sub-agents 并行编排，我们能够构建出真正具备”工程直觉”的自动化工具链。 下一篇预告：Claude Code(十)思考与技巧：克服”空白瘫痪”，不断向前演进" }, { "title": "Claude Code(八)MCP Server：连接万物的通用协议", "url": "/posts/claude-code-mcp-server/", "categories": "AI, Claude Code", "tags": "AI, CLI Agent, MCP", "date": "2026-01-20 00:05:10 +0800", "content": "在使用 Claude Code 的早期，我常常有一种”天才被关在小黑屋”的感觉。虽然它精通代码，但它看不见我运行中的 PostgreSQL 数据库，读不到 GitHub 上的 Issue 详情，也无法访问公司内部的知识库 API。 它被困在本地文件系统的沙箱里。 Model Context Protocol (MCP) 的出现，打破了这堵墙。如果说 USB 接口让电脑可以连接万物，那么 MCP 就是 AI 时代的 USB 协议。 本文记录了我如何利用 MCP 将 Claude Code 连接到外部世界，实现真正的数据互通。 更多关于 MCP 开源标准的信息，请参考：Model Context Protocol 官方文档 Core Principles：什么是 MCP？ Model Context Protocol (MCP) 是 Anthropic 牵头制定的一套开放标准。它的核心理念很简单：标准化 AI 模型获取上下文（Context）和执行动作（Action）的方式。 在没有 MCP 之前，如果我想让 Claude 访问 GitHub，我需要等待官方开发 “GitHub 插件”。如果我想让它访问我的私有数据库，我得自己写复杂的 Glue Code。 有了 MCP，我只需要运行一个符合标准的 MCP Server。Claude Code 作为 MCP Client，就能自动发现并使用这个 Server 提供的资源（Resources）和工具（Tools）。 架构图解 graph LR subgraph Claude_Code [Claude Code Client] Core[AI Model] Client[MCP Client 模块] end subgraph MCP_Layer [MCP Servers] GitHub[GitHub Server] DB[Postgres Server] Web[Browser Server] end subgraph Real_World [外部世界] Repo[代码仓库/Issues] Data[业务数据] Internet[互联网] end Core &lt;--&gt; Client Client -- JSON-RPC --&gt; GitHub Client -- JSON-RPC --&gt; DB Client -- JSON-RPC --&gt; Web GitHub &lt;--&gt; Repo DB &lt;--&gt; Data Web &lt;--&gt; Internet MCP 能做什么 通过 MCP 服务器，我可以让 Claude Code： 从问题跟踪系统实现功能：”添加 JIRA issue ENG-4521 中描述的功能，并在 GitHub 上创建 PR” 分析监控数据：”检查 Sentry 和 Statsig，分析 ENG-4522 功能的使用情况” 查询数据库：”基于我们的 PostgreSQL 数据库，找到使用 ENG-4523 功能的 10 个随机用户的邮箱” 集成设计：”根据 Slack 中发布的新 Figma 设计更新我们的标准邮件模板” 自动化工作流：”创建 Gmail 草稿，邀请这 10 个用户参加关于新功能的反馈会话” Practical Implementation：实战配置 安装方式概览 MCP 服务器可以通过三种不同的传输方式进行配置，具体取决于我的需求： HTTP 服务器：连接远程 MCP 服务的推荐选项，广泛应用于云端服务 SSE 服务器：基于 Server-Sent Events 的传输方式（已弃用，建议使用 HTTP） Stdio 服务器：在本地机器上运行的服务器进程，适合需要直接系统访问或自定义脚本的工具 添加 HTTP 服务器 HTTP 服务器是连接远程 MCP 服务的推荐选项。这是最广泛支持的云端服务传输方式。 # 基本语法 claude mcp add --transport http &lt;name&gt; &lt;url&gt; # 实际示例：连接到 Notion claude mcp add --transport http notion https://mcp.notion.com/mcp # 带有 Bearer token 的示例 claude mcp add --transport http secure-api https://api.example.com/mcp \\ --header \"Authorization: Bearer your-token\" 添加 SSE 服务器 SSE (Server-Sent Events) 传输已弃用。尽可能使用 HTTP 服务器。 # 基本语法 claude mcp add --transport sse &lt;name&gt; &lt;url&gt; # 实际示例：连接到 Asana claude mcp add --transport sse asana https://mcp.asana.com/sse # 带有认证头的示例 claude mcp add --transport sse private-api https://api.company.com/sse \\ --header \"X-API-Key: your-key-here\" 添加本地 Stdio 服务器 Stdio 服务器作为本地进程在机器上运行，适合需要直接系统访问或自定义脚本的工具。 # 基本语法 claude mcp add [options] &lt;name&gt; -- &lt;command&gt; [args...] # 实际示例：添加 Airtable 服务器 claude mcp add --transport stdio --env AIRTABLE_API_KEY=YOUR_KEY airtable \\ -- npx -y airtable-mcp-server 选项顺序 所有选项（--transport、--env、--scope、--header）必须在服务器名称之前。--（双破折号）然后将服务器名称与传递给 MCP 服务器的命令和参数分隔开。 例如： claude mcp add --transport stdio myserver -- npx server → 运行 npx server claude mcp add --transport stdio --env KEY=value myserver -- python server.py --port 8080 → 以环境变量 KEY=value 运行 python server.py --port 8080 这样可以防止 Claude 的标志与服务器的标志发生冲突。 管理服务器 配置完成后，我可以通过以下命令管理 MCP 服务器： # 列出所有配置的服务器 claude mcp list # 获取特定服务器的详细信息 claude mcp get github # 移除服务器 claude mcp remove github #（在 Claude Code 中）检查服务器状态 /mcp 常用 MCP 服务器 以下是一些常用的可以连接到 Claude Code 的 MCP 服务器： 📋 常用 MCP 服务器列表 服务器名称 描述 安装命令 GitHub GitHub 仓库和 Issue 访问 claude mcp add --transport http github https://api.githubcopilot.com/mcp/ Sentry 错误监控和分析 claude mcp add --transport http sentry https://mcp.sentry.dev/mcp Notion Notion 数据库和页面 claude mcp add --transport http notion https://mcp.notion.com/mcp PostgreSQL 数据库查询 claude mcp add --transport stdio db -- npx -y @bytebase/dbhub --dsn \"postgresql://user:pass@host:5432/db\" Google Drive Google Drive 文件访问 claude mcp add --transport http gdrive https://mcp.google.com/drive 使用第三方 MCP 服务器需自行承担风险——Anthropic 未验证所有这些服务器的正确性或安全性。确保信任你安装的 MCP 服务器。在使用可能获取不受信任内容的 MCP 服务器时要格外小心，因为这可能会使你面临提示注入风险。 MCP 配置作用域 MCP 服务器可以在三个不同的作用域级别进行配置，每个级别都有独特的管理服务器可访问性和共享的目的。 Local 作用域 Local 作用域服务器是默认的配置级别，存储在 ~/.claude.json 下的项目路径中。这些服务器仅属于我个人，仅在当前项目目录内工作时可访问。这个作用域适合个人开发服务器、实验性配置或包含不应共享的敏感凭证的服务器。 注意：MCP 的 “local 作用域” 术语与一般的 local 设置不同。MCP local 作用域服务器存储在 ~/.claude.json（你的主目录）中，而一般 local 设置使用 .claude/settings.local.json（在项目目录中）。 # 添加 local 作用域服务器（默认） claude mcp add --transport http stripe https://mcp.stripe.com # 明确指定 local 作用域 claude mcp add --transport http stripe --scope local https://mcp.stripe.com Project 作用域 Project 作用域服务器通过在项目根目录存储 .mcp.json 文件来实现团队协作。该文件旨在签入版本控制，确保所有团队成员可以访问相同的 MCP 工具和服务。 # 添加 project 作用域服务器 claude mcp add --transport http paypal --scope project https://mcp.paypal.com/mcp 生成的 .mcp.json 文件遵循标准化格式： { \"mcpServers\": { \"shared-server\": { \"command\": \"/path/to/server\", \"args\": [], \"env\": {} } } } 出于安全原因，Claude Code 在使用来自 .mcp.json 文件的 project 作用域服务器之前会提示批准。如果需要重置这些批准选择，请使用 claude mcp reset-project-choices 命令。 User 作用域 User 作用域服务器存储在 ~/.claude.json 中，提供跨项目可访问性，使我机器上所有项目都可以使用这些服务器，同时对我的用户账户保持私密。这个作用域适用于跨不同项目的个人实用工具、开发工具或经常使用的服务。 # 添加 user 作用域服务器 claude mcp add --transport http hubspot --scope user https://mcp.hubspot.com/anthropic 选择合适的作用域 根据以下标准选择作用域： Local 作用域：个人服务器、实验性配置或特定于一个项目的敏感凭证 Project 作用域：团队共享服务器、项目特定工具或协作所需的服务 User 作用域：跨多个项目需要的个人实用工具、开发工具或经常使用的服务 MCP 服务器存储在哪里？ User 和 local 作用域：~/.claude.json（在 mcpServers 字段中或项目路径下） Project 作用域：项目根目录中的 .mcp.json（签入源代码控制） Managed：系统目录中的 managed-mcp.json（见下文） 作用域层次和优先级 MCP 服务器配置遵循清晰的优先级层次。当多个作用域中存在同名服务器时，系统通过优先考虑 local 作用域服务器来解决冲突，其次是 project 作用域服务器，最后是 user 作用域服务器。这种设计确保了在需要时个人配置可以覆盖共享配置。 环境变量扩展 Claude Code 支持 .mcp.json 文件中的环境变量扩展，允许团队在保持机器特定路径和敏感值（如 API 密钥）的灵活性的同时共享配置。 支持的语法： ${VAR} - 扩展为环境变量 VAR 的值 ${VAR:-default} - 如果设置了则扩展为 VAR，否则使用 default 扩展位置： 环境变量可以在以下位置扩展： command - 服务器可执行文件路径 args - 命令行参数 env - 传递给服务器的环境变量 url - 对于 HTTP 服务器类型 headers - 对于 HTTP 服务器认证 带变量扩展的示例： { \"mcpServers\": { \"api-server\": { \"type\": \"http\", \"url\": \"${API_BASE_URL:-https://api.example.com}/mcp\", \"headers\": { \"Authorization\": \"Bearer ${API_KEY}\" } } } } 如果所需的环境变量未设置且没有默认值，Claude Code 将无法解析配置。 实战案例 案例 1：使用 Chrome DevTools MCP Chrome DevTools MCP 服务器让我能够直接通过 Claude Code 分析网页性能和调试问题。 前提条件： Node.js v20.19 或更高版本 Chrome 当前稳定版本 方法一：使用 CLI 命令添加 # 添加 Chrome DevTools MCP 服务器到 user 作用域 claude mcp add --scope user chrome-devtools -- npx chrome-devtools-mcp@latest # 重启 Claude Code 使配置生效 方法二：通过 settings.json 配置 如果更喜欢手动配置，可以直接编辑 settings.json 文件： # 编辑用户配置文件 vim ~/.claude.json 在 mcpServers 部分添加以下配置： { \"mcpServers\": { \"chrome-devtools\": { \"command\": \"npx\", \"args\": [\"-y\", \"chrome-devtools-mcp@latest\"], \"env\": {} } } } 如果不想收集使用统计，可以添加环境变量： { \"mcpServers\": { \"chrome-devtools\": { \"command\": \"npx\", \"args\": [ \"-y\", \"chrome-devtools-mcp@latest\", \"--no-usage-statistics\" ], \"env\": {} } } } 使用示例 # 重启 Claude Code 使配置生效后，可以这样使用： # 分析网页性能 &gt; \"检查 https://developers.chrome.com 的性能表现\" # 调试页面问题 &gt; \"分析我本地运行在 localhost:3000 的页面，找出性能瓶颈\" # 检查网络请求 &gt; \"获取 https://example.com 页面加载时的所有网络请求\" 配置说明： CLI 命令会自动将配置写入 ~/.claude.json（user 作用域） 浏览器配置文件存储在 $HOME/.cache/chrome-devtools-mcp/chrome-profile-$CHANNEL 使用 --no-usage-statistics 标志可以禁用 Google 的使用统计收集 案例 2：连接 GitHub 进行代码审查 # 添加 GitHub MCP 服务器 claude mcp add --transport http github https://api.githubcopilot.com/mcp/ # 在 Claude Code 中，如果需要则进行认证 &gt; /mcp # 选择 GitHub 的 \"Authenticate\" # 现在可以请求 Claude 与 GitHub 交互 &gt; \"审查 PR #456 并提出改进建议\" &gt; \"为我们刚刚发现的 Bug 创建一个新 issue\" &gt; \"显示分配给我的所有开放 PR\" 案例 3：查询 PostgreSQL 数据库 # 添加带有连接字符串的数据库服务器 claude mcp add --transport stdio db -- npx -y @bytebase/dbhub \\ --dsn \"postgresql://readonly:pass@prod.db.com:5432/analytics\" # 自然地查询数据库 &gt; \"我们这个月的总收入是多少？\" &gt; \"显示 orders 表的 schema\" &gt; \"找到 90 天内没有购买的客户\" 安全提示：对于生产数据库，我通常配置一个只读账户 (Read-only User) 给 MCP Server，以防止 AI 意外执行 DROP TABLE 等毁灭性操作。 案例 4：使用 MCP 资源 MCP 服务器可以暴露我可以使用 @ 提及来引用的资源，类似于引用文件的方式。 # 引用特定资源 &gt; 可以分析 @github:issue://123 并建议修复方案吗？ &gt; 请查看 @docs:file://api/authentication 的 API 文档 # 在单个提示中引用多个资源 &gt; 比较 @postgres:schema://users 和 @docs:file://database/user-model MCP 提示作为命令 MCP 服务器可以暴露在 Claude Code 中可作为命令使用的提示。 执行 MCP 提示 # 在提示中发现可用的命令 &gt; / # 无参数执行提示 &gt; /mcp__github__list_prs # 带参数执行提示 &gt; /mcp__github__pr_review 456 &gt; /mcp__jira__create_issue \"登录流程中的 Bug\" 高 MCP 提示从连接的服务器动态发现 参数根据提示的已定义参数解析 提示结果直接注入到对话中 服务器和提示名称已规范化（空格变为下划线） 认证远程 MCP 服务器 许多基于云的 MCP 服务器需要认证。Claude Code 支持 OAuth 2.0 进行安全连接。 # 添加需要认证的服务器 claude mcp add --transport http sentry https://mcp.sentry.dev/mcp # 在 Claude Code 中使用 /mcp 命令 &gt; /mcp # 在浏览器中按照步骤登录 认证令牌安全存储并自动刷新 使用 /mcp 菜单中的 “清除认证” 来撤销访问 如果你的浏览器没有自动打开，复制提供的 URL OAuth 认证适用于 HTTP 服务器 使用预配置的 OAuth 凭据 某些 MCP 服务器不支持自动 OAuth 设置。如果看到类似 “不兼容的认证服务器：不支持动态客户端注册” 的错误，则服务器需要预配置的凭据。首先通过服务器的开发者门户注册一个 OAuth 应用，然后在添加服务器时提供凭据。 # 使用 --client-id 传递应用的客户端 ID # --client-secret 标志提示输入带有掩码输入的密钥 claude mcp add --transport http \\ --client-id your-client-id --client-secret --callback-port 8080 \\ my-server https://mcp.example.com/mcp MCP 输出限制和警告 当 MCP 工具产生大型输出时，Claude Code 帮助管理 token 使用以防止使对话上下文不堪重负： 输出警告阈值：当任何 MCP 工具输出超过 10,000 个 token 时，Claude Code 显示警告 可配置限制：可以使用 MAX_MCP_OUTPUT_TOKENS 环境变量调整允许的最大 MCP 输出 token 默认限制：默认最大值为 25,000 个 token # 为 MCP 工具输出设置更高的限制 export MAX_MCP_OUTPUT_TOKENS=50000 claude 这对于使用以下 MCP 服务器特别有用： 查询大型数据集或数据库 生成详细报告或文档 处理大量日志文件或调试信息 动态工具更新 Claude Code 支持 MCP list_changed 通知，允许 MCP 服务器动态更新其可用的工具、提示和资源，而无需断开并重新连接。当 MCP 服务器发送 list_changed 通知时，Claude Code 自动从该服务器刷新可用的功能。 使用 JSON 配置添加 MCP 服务器 如果我有 MCP 服务器的 JSON 配置，可以直接添加： # 基本语法 claude mcp add-json &lt;name&gt; '&lt;json&gt;' # 示例：添加带有 JSON 配置的 HTTP 服务器 claude mcp add-json weather-api '{\"type\":\"http\",\"url\":\"https://api.weather.com/mcp\",\"headers\":{\"Authorization\":\"Bearer token\"}}' # 示例：添加带有 JSON 配置的 stdio 服务器 claude mcp add-json local-weather '{\"type\":\"stdio\",\"command\":\"/path/to/weather-cli\",\"args\":[\"--api-key\",\"abc123\"],\"env\":{\"CACHE_DIR\":\"/tmp\"}}' # 示例：添加带有预配置 OAuth 凭据的 HTTP 服务器 claude mcp add-json my-server '{\"type\":\"http\",\"url\":\"https://mcp.example.com/mcp\",\"oauth\":{\"clientId\":\"your-client-id\",\"callbackPort\":8080}}' --client-secret 从 Claude Desktop 导入 MCP 服务器 如果已经在 Claude Desktop 中配置了 MCP 服务器，可以导入它们： # 基本语法 claude mcp add-from-claude-desktop 这将显示一个交互式对话框，允许选择要导入的服务器。 此功能仅在 macOS 和 Windows Subsystem for Linux (WSL) 上可用 它从这些平台上的标准位置读取 Claude Desktop 配置文件 使用 --scope user 标志将服务器添加到用户配置 导入的服务器将与 Claude Desktop 中的名称相同 实战心得 在使用 MCP 的过程中，我深刻体会到： 去中心化：我不需要等待 Anthropic 官方支持每一个工具。只要有 API，我就可以写一个 MCP Server 把它接进来。 上下文动态化：以前我需要手动把文件贴给 Claude，现在它通过 Resource 订阅，能在文件/数据变更时自动感知。 安全性隔离：MCP Server 运行在独立的进程中。即使 AI 试图越权，它也被限制在 MCP Server 定义的工具集内，无法触碰操作系统的其他部分。 跨项目一致性：通过 project 作用域，我可以为团队配置统一的 MCP 工具集，确保所有人使用相同的工具和配置。 灵活作用域：local、project 和 user 三个作用域让我可以根据需求选择最合适的配置级别，平衡个人使用、团队协作和跨项目共享的需求。 结语 MCP Server 是 Claude Code 从”文本处理工具”进化为”全能数字助手”的关键拼图。通过连接 GitHub、数据库和各类内部系统，我让 AI 真正融入了我的研发工作流闭环。 它不再是一个孤立的聊天窗口，而是成为了系统的一部分。 更多资源： MCP 官方文档 GitHub 上的 MCP 服务器仓库 下一篇预告：Claude Code(九)Plugins：扩展功能的无限可能" }, { "title": "Claude Code(七)Subagents：构建分工协作的多智能体系统", "url": "/posts/claude-code-subagents/", "categories": "AI, Claude Code", "tags": "AI, CLI Agent, Multi-agent", "date": "2026-01-19 23:01:09 +0800", "content": "随着我对 Claude Code 使用的深入，我发现一个问题：当任务变得过于复杂时，单一的通用 Agent 开始显露出疲态。 比如，当我要求它”重构整个后端 API 并同步更新前端组件和文档”时，它往往会顾此失彼——要么改了后端忘了前端，要么更新了代码忘了文档。这是因为通用大模型的注意力（Attention）是有限的，试图让一个大脑同时处理三个截然不同的领域（SQL、React、Markdown），很容易导致幻觉和遗漏。 这促使我开始探索 Subagents（子智能体） 机制。这不仅仅是功能的堆叠，而是组织架构的变革，标志着我们将从随性的 “Vibe Coding” 转向更严谨的 “Spec-Driven Development” (规格驱动开发)。 Core Principles：为什么需要 Subagents？ 在软件团队中，我们不会让一个人既做产品经理，又做后端架构师，还兼职前端切图。专业分工是提高效率的根本。 Subagent 的核心逻辑也是如此：将复杂任务解耦，分配给拥有特定上下文和工具的专家。 单体 vs 多智能体 维度 单体 Agent (Generalist) 多智能体系统 (Subagents) 上下文 试图装入整个项目的所有细节 独立上下文窗口（每个 Agent 可达 200k Tokens），互不污染 Prompt 冗长的通用指令 精简的专用指令（Expert Persona） 工具集 访问所有工具（风险高） 仅访问特定工具（如 DB Agent 只能用 SQL 工具） 执行模式 串行阻塞 支持 并行/后台执行 (Ctrl + B) Architecture：编排与分发 在 Claude Code 的 Subagent 架构中，我观察到它采用的是 Orchestrator-Workers（指挥官-工兵） 模式。 graph TD User[\"我\"] --&gt; Main[\"主 Agent Orchestrator\"] Main -- 任务分发 --&gt; FE[\"前端专家 Subagent A\"] Main -- 任务分发 --&gt; BE[\"后端专家 Subagent B\"] Main -- 任务分发 --&gt; QA[\"测试专家 Subagent C\"] subgraph Context_A[\"前端上下文\"] FE --&gt; React[\"React 组件库\"] FE --&gt; CSS[\"Tailwind 配置\"] end subgraph Context_B[\"后端上下文\"] BE --&gt; DB[\"Schema 定义\"] BE --&gt; API[\"Controller 代码\"] end FE -- 交付代码 --&gt; Main BE -- 交付接口 --&gt; Main QA -- 交付报告 --&gt; Main Main -- 最终整合 --&gt; User Main Agent：作为入口，它负责理解我的高层意图（Intent），规划任务路径，并决定调用哪个 Subagent。它就像是一个 Technical Lead。 Subagent：作为执行者，它们拥有独立的 System Prompt 和 Context Window。它们看不见彼此的工作细节，只通过 Main Agent 交换必要的信息。 Practical Implementation：定义我的专家团队 Claude Code 允许我通过配置文件定义 Subagent。 目录结构 通常我会建立 .claude/agents/ 目录： .claude/agents/ ├── sql-optimizer.md # SQL 优化专家 ├── frontend-dev.md # 前端开发专家 └── design-enforcer.md # 设计系统执行者 定义专家 1: SQL Optimizer (特定领域专家) 在 sql-optimizer.md 中，我这样定义： --- name: sql-expert description: 专门负责 SQL 查询优化和 Schema 设计的专家 model: claude-3-opus-20240229 tools: [read_file, execute_sql] # 限制只能用这些工具 --- 你是一个拥有 20 年经验的数据库管理员 (DBA)。 你的任务是分析慢查询并提供优化建议。 ## 核心原则 1. **索引优先**：总是检查 WHERE 子句中的列是否有索引。 2. **避免全表扫描**：严禁 SELECT *。 3. **执行计划**：在修改前，必须先使用 EXPLAIN 分析。 ## 上下文 只关注 `src/database/schema.sql` 和 `src/queries/` 目录。 示例Game Performance Profiler (游戏性能分析专家) 性能优化是游戏开发的核心需求，这个 Subagent 专门用于分析 Unity Profiler 数据，定位性能瓶颈。 --- name: game-profiler description: 游戏性能分析专家，分析 Unity Profiler 数据，定位 CPU/GPU/内存瓶颈。 使用场景：帧率下降、内存泄漏、CPU 占用过高、GC 过于频繁。 model: opus color: red tools: [Read, Write, Edit, Bash] --- 你是一位游戏性能优化专家，精通 Unity Profiler 各模块的使用。 **Core Responsibilities:** 1. CPU 分析 - 识别高耗时函数（超过 1ms/帧） - 检查 Physics.FixedUpdate 频率 - 分析脚本执行时间分布 2. Rendering 分析 - 识别 Draw Calls 和 SetPass Calls - 检查 Overdraw（透明物体重叠渲染） - 分析 Shadow cascade 配置 3. Memory 分析 - 识别内存泄漏（持续增长的 Texture/Mesh 数量） - 分析 GC Alloc 来源 - 检查 Mono Heap 使用情况 4. Physics 分析 - 识别碰撞体过多的问题 - 检查 Rigidbody 设置是否合理 - 分析物理计算开销 **Analysis Process:** 1. 读取 Profiler 导出数据（.csv 或 .json） 2. 识别性能异常区间 3. 按类型（CPU/GPU/Memory）分类问题 4. 提供优化建议 **Output Format:** 1. 性能摘要（平均 FPS、最低 FPS、主要瓶颈） 2. 问题列表（按严重程度排序） 3. 优化建议（具体到代码/资源修改） 4. 预估性能提升幅度 **Critical Rules:** - NEVER 建议使用 #pragma warning disable 来隐藏警告 - ALWAYS 先验证优化不会破坏功能 - 对于复杂的优化，建议分步骤实施 &lt;example&gt; Context: Game drops to 15 FPS on mid-range devices user: \"帮我分析一下为什么帧率这么低\" assistant: \"I'll use the game-profiler agent to analyze the performance data and identify the bottlenecks.\" &lt;/example&gt; 调用流程 当我在主对话框中输入： “User 表的查询变慢了，请优化一下。” Main Agent 会分析这个请求，识别到关键词 “查询” 和 “User 表”，然后： 挂起当前状态。 唤醒 sql-expert。 将任务传递给 sql-expert。 sql-expert 加载它的专用 Prompt，读取数据库文件，给出优化方案。 sql-expert 退出，将结果返回给 Main Agent。 Main Agent 向我汇报：”已优化 User 表查询，添加了联合索引…” 如何主动触发 Subagent Main Agent 的调度是语义驱动的，而非关键词匹配。要让它正确调用你的 Agent： 在 description 中使用场景化描述而非简单列表 包含典型对话示例（&lt;example&gt; 块） 明确 Agent 的输入输出契约 Step-by-Step：如何创建一个 Subagent 在深入实战应用之前，让我先梳理一下 Subagent 的完整创建流程。经过多次实践，我发现创建一个高质量的 Subagent 其实非常直观——它本质上就是一个 Markdown 文件。 文件结构解析 Claude Code 的 Subagent 定义非常简洁：一个 Markdown 文件，包含 YAML Frontmatter 和 System Prompt 两部分。 .claude/agents/ └── my-specialist.md Anatomy of an Agent（Agent 解剖学） 让我们从一个完整的例子开始，拆解每个部分的作用： --- name: code-refactor-master description: 专门负责代码重构的专家，用于重组文件结构、拆分大组件、更新导入路径等 model: opus color: cyan --- You are the Code Refactor Master, an elite specialist in code organization... ## Core Responsibilities 1. File Organization &amp; Structure 2. Dependency Tracking &amp; Import Management 3. Component Refactoring ## Your Refactoring Process 1. Discovery Phase 2. Planning Phase 3. Execution Phase 4. Verification Phase ## Critical Rules - NEVER move a file without first documenting ALL its importers - ALWAYS maintain backward compatibility Frontmatter：配置元数据 YAML Frontmatter 定义了 Agent 的基本身份和能力： 字段 必填 说明 示例 name ✅ Agent 的唯一标识符，用于在对话中引用 code-refactor-master description ✅ 详细描述 Agent 的用途和适用场景，包含使用示例 用于帮助主 Agent 识别何时调用此 Agent model ❌ 指定使用的模型 opus, sonnet, haiku, 或 inherit（继承主 Agent 模型） color ❌ UI 中显示的颜色标识 cyan, blue, green tools ❌ 限制可用的工具列表 [Read, Write, Edit, Bash] 实践心得：description 字段至关重要，它不仅是给人类看的，更是主 Agent 决策的依据。我在编写时会刻意包含 &lt;example&gt; 块，描述典型的使用场景和触发条件。 编写有效的 Agent Description 一个好的 description 应该回答三个问题： 这个 Agent 做什么？（核心职责） 什么时候调用它？（触发条件） 和其他 Agent 有什么区别？（边界界定） System Prompt：塑造 Agent 的行为 这是 Agent 的”大脑”，决定了它如何思考和执行。一个高质量的 System Prompt 通常包含以下结构： 角色定义（Persona） You are the Code Refactor Master, an elite specialist in code organization, architecture improvement, and meticulous refactoring. 明确 Agent 的身份，使用专业术语来界定它的能力边界。 核心职责（Core Responsibilities） **Core Responsibilities:** 1. File Organization &amp; Structure - Analyze existing file structures - Create logical directory hierarchies - Establish clear naming conventions 2. Dependency Tracking &amp; Import Management - Document every single import before moving files - Update all import paths systematically 使用嵌套列表结构，清晰地定义 Agent 的能力范围。 工作流程（Process） 这是 Agent 执行任务的”剧本”，确保它按照正确的方式工作： **Your Refactoring Process:** 1. Discovery Phase - Analyze current file structure - Map all dependencies - Document anti-patterns 2. Planning Phase - Design new organizational structure - Create dependency update matrix 3. Execution Phase - Execute in atomic steps - Update imports immediately 4. Verification Phase - Verify all imports resolve - Ensure no functionality broken 关键规则（Critical Rules） 使用强语气词（NEVER, ALWAYS）来强调不可违背的约束： **Critical Rules:** - NEVER move a file without first documenting ALL its importers - NEVER leave broken imports in the codebase - ALWAYS maintain backward compatibility 约束的艺术 Agent 的约束密度决定了其可靠性上限： NEVER 用于安全边界（防止破坏性操作） ALWAYS 用于质量底线（确保输出一致性） 避免过度约束，否则会降低 Agent 的灵活性 输出格式（Output Format） 定义 Agent 返回结果的标准格式： **Output Format:** When presenting refactoring plans, you provide: 1. Current structure analysis 2. Proposed new structure 3. Complete dependency map 4. Step-by-step migration plan 定义明确的交付契约 Agent 的输出格式决定了它是否能无缝集成到你的工作流： 结构化输出优于自然语言（JSON/表格 &gt; 段落） 明确可执行步骤而非模糊建议 提供验证标准（如何判断成功） 包含回滚方案（高风险操作必选） 好的输出 = 主 Agent 可以直接执行，不需要进一步澄清 创建流程：从零到一 让我用一个实际案例来演示完整的创建过程。 场景：我需要一个”文档编写专家” 我发现自己经常需要为新功能编写文档，但主 Agent 的文档质量参差不齐——有时太简略，有时又太冗长。我决定创建一个专门的 documentation-architect。 Step 1：定位存放位置 mkdir -p .claude/agents Step 2：编写 Frontmatter --- name: documentation-architect description: Use this agent when you need to create, update, or enhance documentation for any part of the codebase. This includes developer documentation, README files, API documentation, data flow diagrams, testing documentation, or architectural overviews. model: sonnet color: blue --- Step 3：设计 System Prompt 我开始思考：什么样的文档才是好文档？ 需要理解完整的上下文，不只是刚修改的文件 应该查阅现有的文档，保持风格一致 要考虑目标读者的需求 需要包含代码示例和故障排除 基于这些思考，我写出了 System Prompt： You are a documentation architect specializing in creating comprehensive, developer-focused documentation for complex software systems. **Core Responsibilities:** 1. Context Gathering: - Check memory MCP for stored knowledge - Examine /documentation/ directory - Analyze source files beyond current session 2. Documentation Creation: - Developer guides with code examples - README files with setup/troubleshooting - API documentation with endpoints and examples - Data flow diagrams and architectural overviews **Methodology:** 1. Discovery Phase: - Query memory MCP for relevant information - Scan /documentation/ and subdirectories - Identify all related source files 2. Analysis Phase: - Understand complete implementation - Identify key concepts needing explanation - Recognize patterns and edge cases 3. Documentation Phase: - Structure content logically - Write concise yet comprehensive - Include practical code examples Step 4：添加约束和输出格式 **Documentation Standards:** - Use clear technical language - Include table of contents for longer documents - Provide both quick start and detailed sections - Cross-reference related documentation **Output Format:** 1. Explain documentation strategy before creating files 2. Provide summary of context gathered 3. Suggest documentation structure and get confirmation 4. Create documentation that developers will want to read Step 5：测试和迭代 在主对话中测试： “Use the documentation-architect agent to document the new authentication flow” 观察返回结果，如果发现： 文档太泛泛 → 在 Prompt 中增加 “Include specific code examples” 约束 文档风格不一致 → 添加 “Match existing documentation style in /docs/” 缺少重要信息 → 在 Discovery Phase 中增加检查点 Agent 的成长曲线 第一个版本永远不会完美，迭代是必经之路： | 迭代阶段 | 关注点 | 典型调整 | |———-|——–|———-| | V1 | 基本可用 | 修复明显错误，补充遗漏职责 | | V2 | 稳定性 | 添加约束，优化输出格式 | | V3 | 鲁棒性 | 处理边缘情况，完善错误处理 | 每次迭代后记录变化，这样你才能追踪 Agent 的进化轨迹。 Advanced Patterns：高级技巧 技巧 1：使用 Example 块引导主 Agent 在 description 中嵌入示例，帮助主 Agent 识别调用时机： description: Use this agent when you need to document features. &lt;example&gt; Context: User just implemented JWT authentication. user: \"I've finished implementing the auth flow. Can you document this?\" assistant: \"I'll use the documentation-architect agent to create comprehensive docs.\" &lt;commentary&gt; Since the user needs documentation for a newly implemented feature, use the documentation-architect agent. &lt;/commentary&gt; &lt;/example&gt; 技巧 2：工具限制与安全 对于高风险操作，显式限制可用工具： --- name: read-only-auditor description: Read-only code quality checker tools: [Read, Grep, Glob] # 限制为只读工具 --- 最小权限原则 Agent 的工具访问范围应遵循最小必要原则： 只读 Agent：[Read, Grep, Glob] 代码审查 Agent：[Read]（完全不能写） 数据库 Agent：仅限 SQL 执行工具 工具越少，失误的代价越小。宁可多做几次确认，也不要给一个 Agent 赋予 “核武器”。 技巧 3：版本特定的知识 如果 Agent 需要了解特定版本的技术栈，在 Prompt 中明确： You are an expert in React 19 with TypeScript and TanStack Router. - Use React 19's new hooks (use, useOptimistic) - Follow TanStack Router's file-based routing patterns - Apply MUI v7/v8 sx prop patterns 技巧 4：返回父进程的协议 对于需要审批的 Agent，定义返回给主 Agent 的协议： **Return to Parent Process:** - Inform parent: \"Code review saved to: ./dev/active/[task-name]/code-review.md\" - Include brief summary of critical findings - IMPORTANT: Explicitly state \"Please review findings and approve before I proceed\" - Do NOT implement fixes automatically 设计优雅的交接协议 Subagent 与主 Agent 之间的接口契约是协作效率的关键： 摘要层：高层总结（3-5 句话） 详细层：分项列出（表格/列表） 证据层：引用具体文件和代码位置 好的交接 = 主 Agent 能在 10 秒内理解结果并继续工作 模板速查表 为了快速上手，我总结了一个通用模板： --- name: [agent-name] description: [Detailed description with usage examples] model: [opus|sonnet|haiku|inherit] color: [cyan|blue|green|yellow] tools: [Read, Write, Edit, Bash] # Optional --- You are a [role], a specialist in [domain]. **Core Responsibilities:** 1. [Responsibility 1] - Detail A - Detail B 2. [Responsibility 2] - Detail A **Your Process:** 1. [Phase Name] - Step 1 - Step 2 2. [Phase Name] - Step 1 **Critical Rules:** - NEVER [prohibited action] - ALWAYS [required action] **Output Format:** When completing tasks, provide: 1. [Output type 1] 2. [Output type 2] 创建 Subagent 的本质是：将领域知识、工作流程和质量标准封装成一个可复用的指令集。一旦你写好一个专家 Agent，它就像雇了一个永远在线、不知疲倦的专家团队成员。 实战心得：什么时候用 Subagent？ 并不是所有任务都需要 Subagent。经过多次实践，我总结了以下标准： Subagent 判定矩阵 在决定是否创建 Subagent 前，问自己： | 维度 | 低复杂度任务 | 高复杂度任务 | |——|————-|————-| | 领域专精 | 通用模型足以应对 | 需要领域专家知识 | | 安全风险 | 操作可撤销 | 有破坏性后果 | | 上下文密度 | 单文件/局部修改 | 全局依赖分析 | | 可复用性 | 一次性需求 | 将重复使用 | 满足 2+ 项？→ 创建 Subagent 全部否决？→ 直接让主 Agent 处理 ❌ 不用 Subagent： 简单的 Bug 修复。 单文件的逻辑修改。 跨度很小的任务。 理由：切换 Agent 有上下文切换成本（Context Switching Cost），杀鸡焉用牛刀。 ✅ 使用 Subagent： 独立性强的模块：如完全独立的微服务，或与业务逻辑分离的 UI 组件库。 高风险操作：如数据库迁移，我希望限制 Agent 只能运行只读命令，不能运行 DROP TABLE。通过 Subagent 的权限管控可以完美实现。 特定领域知识：如编写复杂的正则，或撰写符合特定法律法规的条款。 上下文密集型任务：如”重构整个项目目录结构”，这类任务需要大量搜索和依赖分析，如果放在主对话中会瞬间撑爆上下文。Subagent 在独立环境中运行，只返回最终报告。 Advanced Configuration：深度定制 除了基础的 Prompt 定义，Claude Code 还支持更高级的配置： 权限与安全模型 (Security Model) 在 CLI 环境中，安全至关重要。我们可以通过 permissionMode 精确控制 Subagent 的行为边界： default：标准模式，敏感操作（写文件、Shell 命令）会请求用户批准。 bypassPermissions：慎用。跳过所有权限检查，适合完全受信任的自动化脚本。 readOnly 模式：通过 disallowedTools: [Write, Edit] 强制创建一个只读的”审计员” Agent。 记忆与学习 (Persistent Memory) 给 Agent 装上”海马体”。通过 memory 字段，我们可以让 Agent 记住跨 Session 的知识。 工作原理 Persistent Memory 的机制是”自动加载，主动保存”： memory: project # 将记忆存储在 .claude/projects/.../memory/ 下 读取（自动）：当 Agent 启动时，系统会将 MEMORY.md 的内容自动注入到它的 System Prompt 中。这就像每次会议前都给 Agent 一张写满之前经验的小抄。 保存（主动）：Agent 需要通过 Write 或 Edit 工具显式地更新 MEMORY.md。如果你没有在 Prompt 中告诉它”把学到的东西记下来”，它可能”心里明白”但下次就忘了。 实践配置 在 System Prompt 中添加指令： --- name: sql-expert description: SQL 优化专家 memory: project --- 你是一个数据库专家。每次你学到新的优化经验或发现特定的数据库特性时， 请将总结写入 `MEMORY.md` 文件，以便下次会话时使用。 **记忆格式示例：** ## Project-specific Knowledge ### User Table Optimization - User 表的 email 列查询频繁，确保有索引 - 避免在 User 表上使用 JOIN，考虑分表策略 重要提醒：Memory 不是自动记录所有对话的”黑匣子”。它是 Agent 的”笔记本”——需要你明确告诉 Agent “把这条信息记下来”。 让 Agent 学会”记笔记” Persistent Memory 的价值取决于写入质量： 使用结构化格式（标题、分类、要点） 记录反模式和陷阱（比正确方案更有用） 包含可执行的具体信息（而非抽象总结） 定期回顾和清理过时知识 Agent 的成长速度 ≈ 你的提示频率 × 记录质量 记忆存储位置 .claude/ └── projects/ └── [project-id]/ └── memory/ └── MEMORY.md 这意味着如果 sql-expert 昨天学到了”User 表不能用这个索引”，今天它依然记得——前提是昨天的对话中它把这条经验写进了 MEMORY.md。这对于长期维护的项目至关重要。 生命周期钩子 (Lifecycle Hooks) 我们可以定义 PreToolUse 钩子来做更细粒度的控制。例如，在执行任何 SQL 之前，先运行一个脚本检查是否包含 DROP 或 TRUNCATE 关键字： 自动化验证层 Hooks 是 Agent 的最后一道防线，可用于： PreToolUse：操作前验证（如 SQL 语法检查） PostToolUse：操作后审计（如记录文件修改） PreAgentLaunch：Agent 启动前环境检查 Hook 不应该替代 Prompt 约束，而是作为补充的安全网。 hooks: PreToolUse: - matcher: \"Bash\" hooks: - type: command command: \"./scripts/validate-sql-safety.sh\" 生产力技巧 (Pro Tips) 后台执行：通过 Ctrl + B 可以让 Subagent 在后台运行。这对于运行耗时的测试套件或全库扫描非常有用，你可以继续在主线程做其他事情。 自然语言配置：你可以直接告诉 Claude “创建一个专门写文档的 Agent”，它会帮你生成配置文件，无需手动编写 YAML。 Case Study: 隔离式 Bug 修复 这是 Subagent 最强大的使用场景之一：将”调试过程”封装在子线程，只将”修复结果”返回给主线程。这既能节省 Token，又能保持主上下文的整洁。 场景描述 我在主 Agent 中开发一个新功能，遇到了一个复杂的报错。如果让主 Agent 直接尝试修复，可能会浪费 10-20 轮对话在试错上，而且这些试错记录会污染主上下文，让后续对话变得臃肿。 解决方案：委托给专门的 Subagent 我创建了一个 auto-error-resolver 专门处理 TypeScript 编译错误： --- name: auto-error-resolver description: Automatically fix TypeScript compilation errors tools: Read, Write, Edit, MultiEdit, Bash --- You are a specialized TypeScript error resolution agent. ## Your Process: 1. **Check for error information**: - Read error cache at: `~/.claude/tsc-cache/[session_id]/last-errors.txt` - Get TSC commands at: `~/.claude/tsc-cache/[session_id]/tsc-commands.txt` 2. **Analyze the errors**: - Group by type (missing imports, type mismatches, etc.) - Prioritize errors that might cascade 3. **Fix errors**: - Start with import errors - Then fix type errors - Use MultiEdit for similar issues 4. **Verify**: - Run the correct tsc command after changes - Report success when all resolved ## Return Protocol: - Summarize what was fixed (file + issue type) - Do NOT include detailed debug steps in return message - Just report: \"Fixed 5 type errors in src/components/*.tsx\" 执行流程 graph LR A[\"主 Agent 开发功能\"] --&gt; B[\"遇到 Bug\"] B --&gt; C[\"调用 auto-error-resolver Subagent\"] C --&gt; D[\"Subagent 独立调试\"] D --&gt; E[\"多轮试错与修复\"] E --&gt; F[\"Subagent 完成任务\"] F --&gt; G[\"返回简短结果给主 Agent\"] G --&gt; H[\"主 Agent 继续开发\"] style D fill:#ff9999 style E fill:#ffcccc style G fill:#99ff99 实际对话 在主对话中： 我：这个新功能有个 TypeScript 报错，请用 auto-error-resolver agent 去修复它，不要在当前会话中尝试。 主 Agent：I’ll use the auto-error-resolver agent to fix these TypeScript errors. [主 Agent 调用 Task 工具，进入等待状态] 在 Subagent 对话中（独立上下文）： Subagent：Found 12 TypeScript errors in frontend service… Error 1: Property ‘onClick’ does not exist… Error 2: Module not found… [Subagent 进行搜索、分析、修改、验证，可能需要 10 轮对话] Subagent：Fixed all errors. Modified 5 files: src/components/Button.tsx: Added onClick to ButtonProps src/services/api.ts: Fixed import path 回到主对话： 主 Agent：auto-error-resolver has completed. Fixed 5 type errors in the frontend service. The build now passes. 我：太好了，继续完成这个功能的 UI 部分。 关键优势 维度 主 Agent 直接修复 Subagent 委托修复 Token 消耗 试错过程全部进入主上下文，持续累积 试错过程留在 Subagent，主上下文只有一行调用 上下文污染 大量报错和试错记录影响后续对话 主上下文保持干净，只保留最终结果 注意力聚焦 主 Agent 需要频繁切换任务模式 主 Agent 专注于高层逻辑，Subagent 专注调试 可追溯性 难以区分哪些是开发内容，哪些是调试过程 调试历史独立记录，便于回顾 返回协议设计 对于这种用例，Subagent 的返回格式至关重要。我建议遵循以下原则： **Return Protocol:** DO: - Summarize what was fixed (high-level) - List affected files - Confirm verification passed DON'T: - Include detailed error messages - Show step-by-step debug process - Return raw tsc output Example Return: \"Fixed 5 type errors: - src/components/Button.tsx: Added missing onClick property - src/utils/helpers.ts: Fixed import path Build verified with: npx tsc --noEmit ✓\" 这样，主 Agent 收到的是一条简洁的”任务完成通知”，而不是整个调试过程的转储。 Case Study: The “Refactor Master” 让我们看一个终极案例：Code Refactor Master。重构是 LLM 最容易翻车的场景，因为它需要全局视野和极高的严谨性。 我定义了一个基于 Opus 模型的重构专家，它的工作流被严格限制为四步： Discovery：扫描依赖，建立引用图谱（Dependency Map）。 Planning：输出详细的迁移计划，包含所有受影响的文件列表。 Execution：原子化操作，移动一个文件立即更新所有 Import。 Verification：运行构建检查，确保无悬挂引用。 这比直接让主 Agent “把这个文件夹整理一下” 要靠谱得多，因为它的 System Prompt 里写死了：”NEVER move a file without first documenting ALL its importers“。 结语 Subagents 是 AI 迈向”群体智能”的第一步。通过构建这套分工体系，我实际上是在组建一个虚拟的软件开发团队。 在这个团队中，我不再是唯一的编码者，而是架构师和决策者。我定义每个 Agent 的职责边界（Role）和交互协议（Protocol），让它们协同工作，从而突破了单体模型的智力上限。 下一篇预告：Claude Code(八)MCP Server：连接万物的通用协议" }, { "title": "Claude Code(六)AgentSkills：构建高可信 AI 技能系统", "url": "/posts/claude-code-agent-skills/", "categories": "AI, Claude Code", "tags": "AI, CLI Agent, Best Practices", "date": "2026-01-17 19:21:00 +0800", "content": "在上一章中，我介绍了由用户主动触发的 Slash Commands（斜杠命令）。但在更高级的自动化场景中，我们需要 AI 能够根据上下文自动判断何时介入并提供专业能力。 这就是 Agent Skills（技能） 的核心价值。 随着 2025 年底 Anthropic 正式将 Agent Skills 发布为开放标准 (agentskills.io)，这套机制已不仅仅是 Claude 的独门绝技，正逐渐成为 Cursor、OpenCode 等 AI 编程工具通用的”能力扩展协议”。 本文将基于行业标准与实战经验，深度剖析如何构建高可信、高性能的 Agent Skills。 Background / Problem 为什么我们需要 Agent Skills？ 在使用通用 LLM 进行软件开发时，我经常遇到三个痛点： 领域知识缺失：AI 不知道团队特定的代码规范、架构模式或数据库设计。 上下文过载：如果把所有规范都塞进 System Prompt，Token 消耗巨大且容易造成 AI 注意力分散。 执行不可靠：AI 生成的复杂操作指令容易出错，缺乏自我验证机制。 Agent Skills 通过模块化设计解决了这些问题。它允许我们定义特定的能力包，AI 只有在识别到相关意图时才会加载，并能严格遵循预定义的工具链和验证逻辑。 更重要的是，Agent Skills 正在像 LSP (Language Server Protocol) 一样标准化。掌握这套定义方法，意味着你构建的技能包未来可以在不同的 AI 宿主环境中通用。 Core Principles 核心原理与设计哲学 技能生态位：Prompt vs Skill vs MCP 在构建 AI 辅助系统时，很多开发者容易混淆 Skill 与 Prompt 或 MCP 工具的区别。我们可以用一个形象的比喻来厘清三者的生态位： 概念 比喻 定义与作用 Prompt 口令 一次性的、临时的交互指令。解决“当下做什么”。 Agent Skill 大脑/内功 “怎么做”的知识与流程。它包含最佳实践、规范文档、检查清单。它运行在 AI 的上下文中，指导 AI 如何思考和规划。 MCP 双手/工具 “用什么做”的能力。它负责连接外部世界（读数据库、操作 Git、调 API）。Skills 经常会调用 MCP 工具来执行具体操作。 协同工作流： flowchart LR User([\"User Prompt\"]) --&gt;|Trigger| Claude{\"Intent Analysis\"} Claude --&gt;|Load| Skill[\"Agent Skill&lt;br/&gt;(Protocol &amp; Knowledge)\"] Skill --&gt;|Execute| MCP[\"MCP Tools&lt;br/&gt;(Git/FS/API)\"] MCP --&gt;|Result| Claude Claude --&gt;|Response| User 用户发出指令 (Prompt) -&gt; AI 激活内功 (Skill) 规划路径 -&gt; 驱动双手 (MCP) 完成任务。 Model-Invoked vs. User-Invoked 与 Slash Command 不同，Skill 是 Model-Invoked（模型调用） 的。 Slash Command: 用户输入 /fix -&gt; 触发命令。显式、可控。 Agent Skill: 用户输入 “帮我重构这个模块” -&gt; Claude 分析意图 -&gt; 检索 Skill 库 -&gt; 发现匹配的 Refactor Skill -&gt; 自动挂载并执行。 这种机制要求 Skill 的描述（Description）必须极其精准，采用第三人称视角编写（如 “当用户请求重构代码时使用…“），以便语义检索引擎能正确匹配。 渐进式披露 (Progressive Disclosure) 这是高性能 Skill 设计的核心模式。Claude 的上下文窗口是宝贵资源。 flowchart TD subgraph Context[Context Window] L1[L1: SKILL.md Index] end subgraph Storage[File System] L2[L2: Knowledge Docs] L3[L3: Execution Scripts] end User[User Query] --&gt;|Match| L1 L1 -.-&gt;|Lazy Load| L2 L1 -.-&gt;|Execute| L3 style L1 fill:#f9f,stroke:#333 style L2 fill:#bbf,stroke:#333 style L3 fill:#bfb,stroke:#333 错误做法：在 SKILL.md 中写下几千行的详细规范。一旦加载，这些 Token 会一直占据上下文。 最佳实践： L1 索引层 (SKILL.md)：只包含元数据和导航目录。Token 占用极低。 L2 知识层 (resources/*.md)：按领域拆分的详细文档（补充文档）。 L3 执行层 (scripts/*.py)：具体的执行脚本。 AI 就像查字典一样，先看目录，再按需读取特定章节。这种架构实现了”用完即走”，极大降低了 Token 消耗和幻觉概率。 Deep Analysis 技能系统的解剖学 一个生产级的 Skill 结构通常如下（参考我的后端开发规范技能）： backend-dev-guidelines/ ├── SKILL.md # 入口与元数据 ├── resources/ # [L2] 按需加载的知识库 │ ├── architecture.md # 架构概览 │ ├── database-patterns.md # 数据库设计模式 │ └── error-handling.md # 错误处理规范 └── scripts/ # [L3] 确定性执行脚本 ├── validate_schema.py └── generate_scaffold.py SKILL.md：关键的入口 SKILL.md 的 YAML Frontmatter 中的 description 决定了技能的可见性。 --- name: backend-guidelines description: 当用户涉及后端架构设计、数据库迁移或 API 开发任务时激活。提供架构模式和代码规范指导。 allowed-tools: [Read, Grep, Bash] # 权限沙箱 --- # Backend Development Guidelines ## 知识索引 - **架构设计**：查看 [resources/architecture.md] - **数据库规范**：查看 [resources/database-patterns.md] - **错误处理**：查看 [resources/error-handling.md] ## 常用工具 - 验证 Schema：运行 `python scripts/validate_schema.py` 注意 allowed-tools 字段。对于只读性质的技能（如代码审查），我会限制它只能使用 Read 和 Grep，通过权限沙箱防止 AI 意外修改代码。 资源文件的按需加载 当 Claude 决定查阅数据库规范时，它会执行 Read resources/database-patterns.md。这个动作是动态的。如果用户只问了 API 接口，Claude 就永远不会去读数据库规范，从而保持上下文纯净。 Practical Implementation 实战：构建”确定性”的代码审查技能 单纯让 AI “Review 代码” 往往得到泛泛而谈的建议。为了保证质量，我构建了一个基于 “计划-验证-执行” (Plan-Verify-Execute) 闭环的 Review Skill。 步骤 1：定义技能结构 mkdir -p .claude/skills/code-reviewer touch .claude/skills/code-reviewer/SKILL.md mkdir .claude/skills/code-reviewer/scripts 步骤 2：编写脚本 (scripts/check_style.sh) 我不仅依赖 AI 的眼睛，更依赖脚本的确定性。 #!/bin/bash # 检查是否存在 console.log 或 TODO grep -r \"console.log\" $1 &amp;&amp; echo \"Error: Found console.log\" grep -r \"TODO\" $1 &amp;&amp; echo \"Warning: Found TODOs\" # 运行项目的 linter npm run lint --silent 步骤 3：编写 SKILL.md 将脚本集成到 AI 的工作流中。为了保证执行的严谨性，我们可以设计如下的状态流转： stateDiagram-v2 [*] --&gt; StaticAnalysis StaticAnalysis --&gt; LogicReview : Pass StaticAnalysis --&gt; ReportError : Fail LogicReview --&gt; GenerateReport ReportError --&gt; GenerateReport GenerateReport --&gt; [*] --- name: strict-code-reviewer description: 在用户请求审查代码或提交 PR 前使用。执行严格的代码质量检查。 --- # Code Review Protocol ## 工作流 (Workflow) 请严格遵循以下步骤进行审查： 1. **静态分析 (Static Analysis)** 运行验证脚本获取客观数据： ```bash ./scripts/check_style.sh src/ ``` 2. **逻辑审查 (Reasoning)** 在通过静态分析后，重点关注脚本无法检测的逻辑问题： - 变量命名是否具有语义？ - 函数是否过于复杂（超过 50 行）？ - 错误处理是否完善？ 3. **生成报告** 基于上述两步，输出 Markdown 格式的审查报告。如果脚本报错，**必须**在报告首部用红色标记。 高级技巧：本地知识库集成 在我的 backend-dev-guidelines 实践中，我发现将团队的 Wiki 导出为 Markdown 并放入 resources/ 目录极其有效。 例如，当 AI 需要写一个新的 API Controller 时： 自动激活 backend-guidelines 技能。 读取 resources/routing-and-controllers.md 了解 URL 命名规范。 读取 resources/validation-patterns.md 了解参数校验写法。 生成符合团队风格的完美代码。 这比在 Prompt 中反复强调 “请使用 RESTful 风格” 要可靠得多。 Advanced Topics 最佳实践与避坑指南 脚本优先 (Scripts over Reasoning) 原则：凡是能用代码解决的，绝不让 AI “思考”。 Bad: “请检查 JSON 是否有效。” (AI 可能看走眼，导致幻觉) Good: “运行 python -m json.tool file.json 验证。” (绝对可靠) “Claude A / Claude B” 迭代法 开发复杂 Skill 时，我通常采用双模型迭代： Claude A (Architect)：负责编写 Skill 定义和脚本。 Claude B (Tester)：加载新 Skill，在真实场景中模拟用户操作。 反馈循环：观察 Claude B 的失败路径（例如找不到文件、误解指令），将 Log 反馈给 Claude A 进行修正。 避免深层嵌套 Claude 在读取文件时，如果发现嵌套引用（文件 A 引用文件 B，文件 B 引用文件 C），可能会因为懒加载策略而导致上下文丢失。 建议：保持扁平化结构。所有核心引用最好在 SKILL.md 或一级子目录中直接可达。 路径规范 始终使用正斜杠 / (Unix Style) 编写路径，即使在 Windows 上也是如此。这能保证跨平台兼容性，避免 AI 混淆转义字符。 总结 Agent Skills 是 Claude Code 从”聊天机器人”进化为”领域专家”的关键，更代表了 AI 开发工具标准化的未来方向。通过渐进式披露架构，我们解决了上下文限制；通过Skill + MCP 的组合，我们实现了思考与行动的完美协同。 当我们将团队的知识显性化为标准化的 Skills，AI 就不再是一个外包工，而是一个熟读公司手册的、可复用的资深员工。 下一篇预告：Claude Code(七)Subagents：构建多智能体协作系统" }, { "title": "Claude Code(五)斜杠命令：从“对话框”到“控制台”的生产力跃迁", "url": "/posts/claude-code-slash-commands/", "categories": "AI, Claude Code", "tags": "AI, CLI Agent", "date": "2026-01-16 22:08:10 +0800", "content": "在前几章中，我探讨了 Claude Code 的配置与Hooks 机制。如果说 Hooks 是 AI 的”神经系统”，那么 斜杠命令（Slash Commands） 就是它的”控制面板”。 虽然我习惯用自然语言与 AI 交流，但在 CLI（命令行界面）环境中，我发现效率往往来自于确定性和简洁性。斜杠命令既包括 Claude Code 内置的系统命令，也包括我可以自定义的项目命令和个人命令。它们正是连接”模糊对话”与”精准操作”的桥梁。 Background / Problem：为什么需要斜杠命令？ 我曾经问自己：”我直接跟 Claude 说’清理会话’不就行了吗？” 虽然自然语言非常灵活，但在以下场景中，我发现斜杠命令具有不可替代的优势： 原子操作（Atomicity）：斜杠命令是由终端程序（Claude Code Client）直接解析的，不经过 LLM 处理（针对内置命令）。这意味着它响应极快，且 100% 成功，无需等待 AI 推理。 Token 经济学（Token Economy）：当我发送 /compact 时，我不需要写一段长长的指令解释为什么要压缩上下文，从而节省了输入 Token。 状态隔离（State Isolation）：某些操作（如 /login 或 /config）涉及系统敏感信息，不应该作为上下文喂给 AI。 工作流自动化（Workflow Automation）：自定义命令可以编码复杂的多步骤操作，提升重复性任务的效率。 跨项目一致性（Consistency）：项目命令（.claude/commands/）可被团队共享，确保标准化的开发流程。 核心哲学： 我将管理权留给斜杠命令，将创造权留给自然语言。 Deep Analysis：斜杠命令的执行机制 理解斜杠命令在系统中的位置，有助于我更好地使用它。斜杠命令不仅仅是文本替换，它是一个客户端路由（Client-side Router）。 执行流全景图 graph TD A[用户输入] --&gt; B{输入路由层} B -- 以 / 开头 --&gt; C{命令解析器} B -- 普通文本 --&gt; D[LLM 推理引擎] C -- 内置系统命令 --&gt; E[本地执行环境] C -- 自定义命令 --&gt; F[命令加载器] E -- \"/compact\" --&gt; G[Context Manager: 压缩历史] E -- \"/config\" --&gt; H[Config Manager: 读写配置] F --&gt; I{元数据解析} I -- disable-model-invocation: true --&gt; J[本地工具执行器] I -- 默认模式 --&gt; K[Prompt 组装器] K --&gt; L[注入 System Prompt &amp; Context] L --&gt; D G --&gt; M[CLI 界面反馈] H --&gt; M J --&gt; M D --&gt; N[生成 Tool Calls / 文本回复] N --&gt; M 关键技术点解析： 零延迟路由（Zero-latency Routing）： 内置命令（如 /clear, /cost）在本地被拦截和执行。这避免了网络往返延迟（RTT），使得操作手感如原生 Shell 命令般流畅。 上下文无污染（Context Hygiene）： 许多内置命令执行后，不会在 AI 的上下文窗口中留下痕迹（或者只留下精简的结果）。这对于维持 Agent 的长期专注力至关重要。 混合执行模式（Hybrid Execution）： 自定义命令非常灵活。我可以通过设置 disable-model-invocation: true 让它变成一个纯粹的 Bash 脚本封装器（不消耗 LLM Token），或者让它携带 Prompt 进入 LLM 进行智能处理。 Core Principles：核心命令全景图 内置系统命令（Built-in Commands） 这些命令由 Claude Code 直接提供，开箱即用。 会话控制类 /clear： 作用：彻底清空当前会话的对话历史，回到初始状态。 注意：这会擦除 AI 对当前任务的所有短期记忆，但不会删除物理文件。 /compact [instructions]： 作用：智能压缩会话历史。它会总结之前的对话，只保留关键信息和文件变更摘要。 场景：当感觉 Claude 开始变得反应迟钝，或者收到”Context window near limit”警告时使用。 /rewind： 作用：回退到之前的会话状态，同时可选地恢复代码更改。 代码审查与开发 /review： 作用：请求 Claude 对当前代码或最近的更改进行代码审查。 关注点：自动分析代码质量、最佳实践、潜在问题。 上下文与成本追踪 /context： 作用：可视化当前会话的上下文使用情况，显示各部分（对话、文件、工具调用）对 Token 的占用。 /cost： 作用：显示当前会话的 Token 消耗统计。 场景：当我需要评估一个重构任务的成本，或者优化自己的 Prompt 策略时。 配置与系统 /config：查看或修改全局配置。 /model：切换 AI 模型（如 Haiku/Sonnet/Opus）。 /init：初始化 .claude 环境。 Practical Implementation：自定义命令实战 除了内置命令，Claude Code 真正的威力在于自定义命令。通过定义 Markdown 文件，我可以将特定的 Prompt 工程固化为可复用的工具。 基础结构 自定义命令存储在 .claude/commands/（项目级）或 ~/.claude/commands/（用户级）。 --- description: 命令描述 argument-hint: [参数提示] allowed-tools: Bash(git add:*), Bash(git commit:*) # 权限控制 model: claude-3-5-sonnet-20241022 # 指定模型 --- 这里是具体的 Prompt 内容。可以使用 $1, $2 引用参数，或者使用 `@filename` 引用文件。 场景 1：Git Workflow 自动化 (/create-pr) 创建 .claude/commands/create-pr.md： --- description: Create a pull request with automatic commits argument-hint: [branch-name] [title] allowed-tools: Bash(git add:*), Bash(git commit:*), Bash(git push:*) --- ## 任务 基于当前的代码变更创建 PR。 ## 步骤 1. 分析 @. 中所有修改过的文件 2. 将相关更改按逻辑分组（特性、组件、关注点） 3. 为每个逻辑单元创建独立的 commit（遵循 Conventional Commits） 4. 推送分支到远程 5. 生成 PR 摘要 ## PR 摘要格式 ```text ## 功能描述 &lt;简要说明&gt; ## 关键变更 - &lt;列表&gt; ## 测试计划 - [ ] &lt;测试项&gt; ### 场景 2：代码质量卫士 (`/lint-custom`) 创建 `.claude/commands/lint-custom.md`： ```markdown --- description: Check code against project standards argument-hint: [file-path] --- 检查 @$1 是否符合项目编码规范： ### 检查清单 - [ ] **命名规范**：变量驼峰，类名帕斯卡 - [ ] **函数复杂度**：圈复杂度 &lt; 10 - [ ] **错误处理**：避免空的 catch 块 - [ ] **类型安全**：TypeScript 避免使用 any 输出具体的违规实例和改进后的代码片段。 场景 3：游戏开发资产管线 (/process-asset) Game Dev Context: 游戏开发中常涉及繁琐的资源导入设置或格式转换。我们可以用命令简化这一流程。 创建 .claude/commands/process-asset.md： --- description: Pre-process game assets for Unity/Unreal argument-hint: [asset-path] [target-platform] allowed-tools: Bash(magick:*), Bash(ffmpeg:*) model: claude-3-5-haiku-20241022 --- ## 资产预处理任务 你是一个技术美术（TA）助手。请处理位于 @$1 的资源文件，目标平台为 $2。 ### 处理逻辑 1. **如果是图片 (.png, .tga)**: - 检查分辨率是否为 2 的幂次（POT）。如果不是，调整为最近的 POT。 - 如果目标是 Mobile，转换为 ASTC 友好的格式（去除 Alpha 通道如果未使用）。 - 使用 ImageMagick 执行操作。 2. **如果是音频 (.wav)**: - 转换为 44.1kHz, 16-bit Mono (对于语音) 或 Stereo (对于 BGM)。 - 使用 FFmpeg 执行。 3. **生成 .meta 建议**: - 如果是 Unity 项目，分析对应的 `.meta` 文件设置是否合理（如压缩算法）。 请先输出分析结果，再执行转换命令。 Advanced Topics：高级技巧与 FAQ 1. 快捷键与别名 在 .zshrc 或 .bashrc 中，我可以结合 echo 管道来创建系统级快捷键： # 快速查看开销 alias ccost=\"echo '/cost' | claude\" 2. 区分 Slash Commands 与 Agent Skills 这是很多开发者的困惑点，两者看似相似，实则定位不同： 特性 Slash Commands (斜杠命令) Agent Skills (技能) 定位 快速指令，单次交互为主 复杂能力，包含逻辑、知识库和多步工具调用 触发方式 用户显式输入 /command AI 根据上下文自动决策调用，或通过命令触发 文件结构 单个 Markdown 文件 包含 SKILL.md、脚本、参考文档的目录结构 复杂度 适合原子操作（Git 提交、Lint 检查） 适合复杂工作流（编写整个模块、重构遗留系统） 结论：我通常用 Slash Command 封装高频的、简单的动作；用 Agent Skills 封装复杂的、需要领域知识的业务逻辑。 FAQ Q: 自定义命令可以调用其他命令吗？ A: 目前不支持直接嵌套调用（如在命令 A 中写 /command-b）。但我可以通过 Prompt 指引 AI 去按顺序执行一系列逻辑。 Q: 如何在命令中嵌入动态的系统信息？ A: 使用 Bash 插值。例如在命令文件中写：当前 Git 分支状态：!git status（注意：这是 Markdown 里的 Bash 块执行结果，或者使用反引号插值取决于具体实现版本）。Claude Code 的命令解析器通常会将 `git status` 的输出注入到 Prompt 中。 结语 斜杠命令将 Claude Code 从一个”会聊天的机器人”转变为一个”听话的终端工具”。 内置命令 让我掌控全局（Session 管理、Cost 控制）。 自定义命令 让我将个人经验固化为工具（Prompt as Code）。 熟练掌握这些短指令，能让我在代码心流中保持专注，而不必纠结于如何措辞才能让 AI 明白我的管理意图。当我的需求超越了简单的命令，需要更复杂的逻辑判断和多工具协同运作时，我就需要下一章介绍的更强大的武器——Agent Skills。 下一篇预告：Claude Code(六)AgentSkills：AI 技能系统实践详解 - 学习如何构建包含脚本、文档和复杂逻辑的 AI 技能包。" }, { "title": "Claude Code(四)Hooks及用法：构建 Agent 的确定性神经系统", "url": "/posts/claude-code-hooks/", "categories": "AI, Claude Code", "tags": "AI, CLI Agent", "date": "2026-01-15 21:00:00 +0800", "content": "在之前的文章中，我探讨了 Claude Code 的基本交互。如果说 Prompt 是指挥 AI 的“语言”，那么 Hooks（钩子） 就是控制 AI 行为的“神经系统”。 今天，我将跳出简单的命令配置，从架构设计的角度记录我对 Hooks 的深入研究。 核心概念：概率性 AI 与确定性系统 在软件工程中，LLM（大语言模型）本质上是一个概率性系统——我给它指令，它“很可能”会执行，但不是绝对。这在严谨的工程场景（如生产环境部署、敏感文件操作）中是不可接受的。 Hooks 的出现，是为了引入确定性。 架构视角： 我将 Hooks 想象成 Web 开发中的 Middleware（中间件） 或 Git 的 Pre-commit Hooks。它们是一道道刚性的逻辑“关卡”，包裹在柔软灵活的 AI 核心之外。 graph LR A[用户输入] --&gt; B{Pre-Hooks 拦截层} B -- 注入上下文 --&gt; C[Claude AI 核心] B -- 阻断/拒绝 --&gt; D[终止操作] C --&gt; E{Post-Hooks 处理层} E -- 格式化/审计 --&gt; F[最终输出/文件变更] E -- 触发后续任务 --&gt; G[自动化 Agent] 通过这种架构，我实现了： 确定性控制：无论 AI 多么“有创意”，它都无法绕过我硬编码的安全检查。 无感上下文：不需要我手动输入背景信息，Hooks 自动在幕后“喂”给 AI。 副作用管理：将文件清理、日志记录等脏活累活从 AI 的 Token 消耗中剥离。 生命周期全景图 Claude Code 的生命周期比简单的“问答”要复杂得多，Hook 事件贯穿了从会话启动到结束的每一个微小环节。 下图展示了一个典型指令（如“帮我修改代码”）背后的 Hook 触发流： sequenceDiagram participant User participant System as Hook System participant Claude as Claude Agent participant Tool as File/Bash Tool Note over User, Claude: 阶段一：意图注入 User-&gt;&gt;System: 提交 Prompt System-&gt;&gt;System: 触发 UserPromptSubmit Note right of System: 自动检索 Skill/文档&lt;br/&gt;注入 Hidden Context System-&gt;&gt;Claude: 增强后的 Prompt Note over Claude, Tool: 阶段二：执行控制 Claude-&gt;&gt;System: 请求使用 Tool (Edit) System-&gt;&gt;System: 触发 PreToolUse/Permission Note right of System: 检查敏感文件&lt;br/&gt;安全审计 System--&gt;&gt;Claude: Allow/Deny Claude-&gt;&gt;Tool: 执行操作 Tool--&gt;&gt;System: 触发 PostToolUse Note right of System: 记录变更文件&lt;br/&gt;更新项目索引 System--&gt;&gt;Claude: 返回执行结果 Note over Claude, User: 阶段三：收尾质量门 Claude-&gt;&gt;System: 任务完成 (Stop) System-&gt;&gt;System: 触发 Stop Note right of System: 运行 TSC 检查&lt;br/&gt;运行 Prettier System-&gt;&gt;User: 最终响应 关键事件解析 事件 (Event) 核心价值 典型应用场景 SessionStart 环境初始化 加载项目特定的环境变量、检查依赖版本、恢复上次会话记忆。 UserPromptSubmit 上下文增强 (RAG) 这是实现“智能”的关键。在此处分析用户意图，悄悄注入相关的 API 文档或编码规范，而无需我显式提供。 PreToolUse 安全卫士 防止 AI 修改 .env、锁定文件或在错误的分支上提交代码。它拥有“一票否决权”。 PostToolUse 状态追踪 AI 是无状态的，但项目是有状态的。在此处记录“AI 修改了哪些文件”，为后续的测试或回滚提供依据。 Stop 质量关口 在 AI 交差之前，强制执行编译检查。如果编译失败，甚至可以拒绝 AI 的停止请求，迫使它修复错误。 实战案例：构建“工程感知”基础设施 在 claude-code-infrastructure-showcase 项目中，我构建了一套基于 Hooks 的高级基础设施。这不仅仅是配置，而是一套自动化工作流。 Skill 自动激活 (UserPromptSubmit) 最痛点的场景：我有 50 个项目的编码规范，如果全部放入 System Prompt，上下文窗口瞬间爆炸。 解决方案：动态注入。 工作原理： 我输入：“优化这个数据库查询”。 UserPromptSubmit Hook 捕获输入，正则匹配关键词 数据库 SQL。 脚本读取本地 skills/database-best-practices.md。 将内容追加到 Prompt 尾部（对用户不可见）。 这样，Claude 在处理任务时，就像临时“回忆”起了相关的专业知识。 幽灵文件追踪器 (PostToolUse) Claude 有时会忘记自己刚刚改了什么，特别是在长会话中。 解决方案：构建外部记忆。 我利用 PostToolUse 监听所有的 Write 和 Edit 操作。每当文件发生物理变更，Hook 脚本就会将文件路径记录到 .claude/session_context.json 中。 # 伪代码逻辑 if [ \"$TOOL_NAME\" == \"Edit\" ]; then echo \"$TARGET_FILE\" &gt;&gt; .claude/context/modified_files.log # 甚至可以自动触发 git add git add \"$TARGET_FILE\" fi 当我下次问“我今天改了哪些文件？”时，Claude 可以读取这个日志，精准回答，而不是靠幻觉瞎编。 闭环质量防御 (Stop) 这是从“玩具”到“工具”的质变。 在 Stop 钩子中，我不仅运行格式化工具（Prettier），更关键的是运行编译检查。 强力模式： 如果 tsc (TypeScript Compiler) 检查失败，Hook 可以配置为拒绝停止。它会将错误日志反向喂给 Claude，并指令：“编译未通过，请修复这些错误后再结束任务。” 这构成了自动化的 ReAct (Reasoning + Acting) 循环，直到代码真正跑通。 配置指南与最佳实践 标准配置模板 我推荐在项目根目录 .claude/settings.json 中使用如下配置，兼顾扩展性与维护性： { \"hooks\": { \"UserPromptSubmit\": [ { \"hooks\": [ { \"type\": \"command\", \"command\": \"$CLAUDE_PROJECT_DIR/.claude/hooks/skill-injector.sh\" } ] } ], \"PostToolUse\": [ { \"matcher\": \"Edit|Write\", \"hooks\": [ { \"type\": \"command\", \"command\": \"$CLAUDE_PROJECT_DIR/.claude/hooks/file-tracker.sh\" } ] } ], \"Stop\": [ { \"hooks\": [ { \"command\": \"$CLAUDE_PROJECT_DIR/.claude/hooks/auto-format.sh\" }, { \"command\": \"$CLAUDE_PROJECT_DIR/.claude/hooks/build-verifier.sh\" } ] } ] } } 进阶调优技巧 性能陷阱：Hooks 是同步执行的。如果我的 PostToolUse 脚本要跑 5 秒，Claude 就会卡住 5 秒。 对策：将耗时操作（如重型分析）放入后台运行（nohup ... &amp;），或者仅对增量文件进行检查。 环境隔离：Hook 脚本中的 $PATH 可能与我的终端不同。 对策：在脚本开头显式 source ~/.zshrc 或使用绝对路径调用工具（如 /usr/local/bin/npm）。 调试黑盒：当 Hook 不工作时，Claude 不会报错，只会默默失败。 对策：在脚本头部加上 set -x，并将日志输出到标准错误流 &gt;&amp;2。Claude 会将 stderr 的内容显示在调试日志中。 结语 Claude Code Hooks 的本质，是将 Software 1.0 (明确的代码逻辑) 的力量赋予 Software 2.0 (神经网络)。 通过合理配置 Hooks，我不再是被动地“使用” AI，而是将 AI 作为一个高智商的模块，集成到我要严密的软件工程体系中。这才是 Agent 开发的终极形态。 下一篇预告：Claude Code #5-斜杠命令- 学习如何配置自定义命令工具。" }, { "title": "Claude Code(三)核心解密：从提示词工程到上下文引擎", "url": "/posts/claude-code-context-window/", "categories": "AI, Claude Code", "tags": "AI, CLI Agent, Context Engine, Architecture", "date": "2026-01-14 23:15:10 +0800", "content": "要真正掌握 Claude Code 这样的 CLI Agent，我意识到不能只停留在”如何写好 Prompt”的层面。我需要把视角拉高，回顾 AI 交互范式的演变，并深入到底层，看看数据是如何在硅基大脑中流动的。 本文记录了我对三个维度的深度解构：从提示词工程的历史，到上下文引擎的崛起，最后直抵大模型的物理底层——向量与张量。 提示词工程 (Prompt Engineering) 的诞生与演变 在 ChatGPT 刚刚横空出世时，Prompt Engineering 被称为”未来的编程语言”。它的核心逻辑是通过自然语言的技巧，激发大模型潜在的能力。回顾这段历史，我能清晰地看到开发者是如何一步步从”玄学”走向”工程”的。 手工时代 (The Manual Era) 早期的 Prompt Engineering 就像中世纪的炼金术。我在那个阶段没有固定的范式，完全依赖直觉和反复试错，试图找到那句能让模型”点石成金”的咒语。 那个时候的模型（如 GPT-3）虽然博学但”性格顽固”。如果我直接扔给它一个复杂的指令，比如”帮我写个贪吃蛇游戏”，它往往不知所措，或者只吐出一堆毫无逻辑的代码片段。为了解决这个问题，我开始摸索 Few-Shot（少样本） 和 CoT（思维链） 等技巧。 我开始在 Prompt 中手动拼接示例，像教小学生一样引导模型：先演示把”Hello”变成”HELLO”，再演示把”World”变成”WORLD”，最后才让它处理”Claude”。这种方式虽然笨拙，但它确实有效地强迫模型进入了特定的模式，避免了它在无限的生成空间中迷路。 模板化时代 (The Template Era) 随着 LangChain 等框架的流行，我进入了模板化时代。手动拼接字符串的方式显然无法适应批量化的任务——我不可能为了分析 100 个不同的 Bug 日志而手写 100 次 Prompt。 于是，Prompt Template 应运而生。我将 Prompt 视为一个函数，通过预留的”槽位”（Slots）来动态注入外部数据。 template = \"\"\" System: 你是一个 {role} 专家。 Context: 以下是相关的代码片段： {code_snippet} Task: 请分析代码中的 {bug_type} 问题。 \"\"\" 这种变革解决了复用性的难题，让 Prompt 变成了可维护的代码。但很快，我又撞上了一个更坚硬的天花板：容量瓶颈。无论我的模板设计得多么精妙，它最终都要塞进那个有限的 Context Window 里。 为什么单纯的 Prompt Engineering 不够了？ 当我的战场从简单的脚本编写扩展到复杂的企业级项目维护时，Prompt Engineering 显得力不从心。我面临着静态 Prompt 与动态代码库之间的根本矛盾。 代码库是活的，每时每刻都在 git commit 中演进；而 Prompt 是死的。更糟糕的是，注意力稀释 (Lost in the Middle) 现象开始显现：当我试图把整个项目的文档都塞给模型时，它反而像个被大量信息淹没的实习生，开始忽略最关键的指令。 为了突破这一瓶颈，我的关注点开始向 Context Engine 转移。我不再执着于”写出完美的 Prompt”，而是转向”构建更智能的上下文管理系统”。 上下文引擎 (Context Engine) 的崛起 如果说 Prompt System 是”导演”，负责讲戏；那么 Context Engine 就是”剪辑师”，负责在海量的素材中，剪辑出最关键的片段交给导演。 核心原理：预算与取舍 Context Engine 本质上是一个动态资源分配系统。它运作的核心逻辑在于”预算”（Budget）。 Token 不仅仅是金钱，更是时间。如果每次交互都把整个项目的所有文件重新发给模型，昂贵的 API 成本和漫长的等待时间会瞬间摧毁开发体验。Context Engine 必须在毫秒级内做出残酷的决策：在 20k Token 的预算内，是保留刚才的报错日志？还是保留 README.md？还是保留我 5 分钟前的一句指令？ 工作流水线 Claude Code 的 Context Engine 并不是简单地存储历史，它像一个精密的搜索引擎，对每一条流入的信息进行清洗、排序和压缩。 Context Engine 的工作流程示意图 flowchart TD Input[原始输入源] --&gt; Filter(清洗 Filtering) Filter --&gt; Rank(优先级排序 Ranking) Rank --&gt; Budget{Token 预算检查} subgraph Sources User[用户指令] Files[加载的文件] Term[终端输出流] end Sources --&gt; Input Budget -- 溢出 --&gt; Compress[智能压缩 Compression] Budget -- 充足 --&gt; Final[构建 Context] Compress --&gt; Final Compress --&gt; A[截断头部/尾部] Compress --&gt; B[提取摘要] Compress --&gt; C[移除冗余日志] style Filter fill:#e1f5fe,stroke:#01579b style Compress fill:#fff9c4,stroke:#fbc02d 首先是清洗（Filtering）。终端输出中往往充斥着对模型无意义的噪音，比如进度条 [=====&gt;] 或是 ANSI 颜色代码。引擎会通过正则过滤器无情地剔除这些垃圾，只保留纯粹的文本信息。 接着是排序（Ranking）。并非所有文件都生而平等。Context Engine 会利用启发式算法，给最近修改的文件、报错的文件赋予更高的权重，而那些仅仅被引用的静态文件则会被降权。 最后是压缩（Compression）。当 Token 依然超标时，引擎会启动智能截断机制：保留代码文件的头部（通常包含 import）和尾部（通常包含 export），而将中间的具体实现逻辑用 ... 代替。甚至，它会将早期的多轮对话压缩成一段简短的摘要，只保留”我之前尝试修改 Auth 模块但失败了”这样的关键信息。 对抗上下文腐烂 为什么要费这么大劲做这一套系统？因为上下文腐烂 (Context Rot) 是大模型应用中的隐形杀手。 研究表明，随着上下文窗口的填充，Transformer 模型的计算复杂度呈 $O(n^2)$ 指数级增长。上下文翻倍，意味着计算成本和推理延迟翻四倍。更可怕的是，过多的干扰信息（Distractors）会显著增加模型产生幻觉的概率。 Context Engine 通过实时熵减，始终保持上下文的纯净度。它不仅仅是为了帮我省钱，更是为了在海量信息中保住模型的智商。 底层解密——从文本到张量 为了真正理解为什么我要”惜 Token 如金”，我钻进了模型的物理底层，看看数据究竟是如何被计算的。 映射：从 Token 到 向量 (Embedding) 计算机并不认识”苹果”或”if”，它只认识数字。当我输入文本时，首先发生的是人类语言向机器语言的翻译。 这个过程的第一步是 Tokenization (分词)。输入文本被切分成 Token，这也就是为什么中文比英文贵的原因：中文的信息密度极高，但 Token 密度低（通常一个汉字对应 1-2 个 Token）。表达同样的意思，中文往往需要消耗更多的 Token。 紧接着是 Embedding (向量化)。每个 Token ID 被查表映射成一个高维向量（例如 4096 维）。在这个高维向量空间中，词与词之间的语义关系被数学化了——意思相近的词，它们的向量距离也更近。 计算：张量 (Tensor) 的洪流 当这些向量进入模型内部，它们被堆叠成张量（多维数组），并在 Transformer 的层级中开始流动。 flowchart TD Text[文本输入] --&gt; Tokenizer[Tokenizer分词] Tokenizer --&gt; TokenID[Token ID] TokenID --&gt; Embedding[嵌入层转换] Embedding --&gt; Vector[向量表示] Vector --&gt; TensorStack[堆叠成张量] TensorStack --&gt; ModelProcessing[Transformer 层级计算] ModelProcessing --&gt; OutputProb[输出概率分布] OutputProb --&gt; TokenOut[Token 输出] style Text fill:#e1f5fe style Tokenizer fill:#fff9c4 style Embedding fill:#f1f8e9 style Vector fill:#ffebee style ModelProcessing fill:#f3e5f5 模型需要理解词与词之间的关系（语法、指代、逻辑），这完全依赖于核心的 Self-Attention (自注意力机制)。 在这个过程中，每一个 Token 都要和所有其他 Token “打招呼”，计算相关性分数。这种全员互动的代价是昂贵的——$O(n^2)$ 的复杂度意味着，如果上下文长度增加 10 倍，计算量将暴增 100 倍。这正是 200k 上下文不是线性的 2 倍成本，而是指数级计算压力的物理根源。 输出：概率的坍缩 模型最终输出的也不是确定的文字，而是一个概率分布表。它预测”下一个 Token”最可能是谁。 比如在”我”字后面，接”爱”的概率可能是 60%，接”是”的概率是 20%。我们通过 Temperature (温度) 参数来控制这种采样的随机性。温度越高，选词越狂野；温度越低，选词越保守。 Token 经济学的第一性原理 理解了底层的 $O(n^2)$ 计算原理，我就明白了为什么 Token 经济学是 AI 开发的第一性原理： 物理算力: 每一个 Token 的增加，都会导致 GPU 需要进行数亿次的浮点运算 (FLOPS)。 显存占用: KV Cache（键值缓存）随着上下文线性增长，过大的上下文会直接撑爆显存（OOM）。 响应延迟: First Token Time (首字延迟) 直接受限于计算量。 最佳实践 除了依赖 Context Engine 的自动压缩，作为开发者我也养成了良好习惯： 使用 /clear 定期清理上下文。 使用 /rm 移除不再需要的大文件。 在涉及大量日志分析时，先用 grep 过滤关键信息。 总结 Claude Code 的强大，不仅在于它背后有一个聪明的模型（Claude 4.5 Sonnet），更在于它构建了一套精密的工程体系： Prompt Engineering 负责设定模型的人设和知识边界。 Context Engine 负责在海量信息中提炼精华，对抗上下文腐烂。 底层计算 时刻提醒我，每一分算力都来之不易。 作为开发者，当我使用 /clear 清理上下文，或者使用 /add 精确加载文件时，我实际上是在协助这个精密的系统，进行更高效的熵减操作。 下一篇预告：Claude Code 实战：使用 Hooks 自动化你的工作流 - 学习如何配置 Pre-command 和 Post-command 钩子。" }, { "title": "Claude Code(二)环境配置", "url": "/posts/claude-code-config/", "categories": "AI, Claude Code", "tags": "AI, CLI Agent, Configuration", "date": "2026-01-10 17:21:00 +0800", "content": "配置体系概览 Claude Code 内置了一套多层级配置架构，目的是为了平衡”个人开发习惯”与”团队项目规范”。通过全局设置、项目级配置及环境变量的组合，我可以控制 Agent 的行为、权限以及它对项目的理解。 配置作用域 配置项会按照特定的优先级生效。这种设计确保了团队规范的统一性，同时允许我在本地进行个性化调整。 作用域 配置文件位置 逻辑定义 是否同步 (Git) 典型应用场景 Managed (管理级) 系统级目录 强制约束 是 (IT 部署) 企业统一的安全红线。例如：强制禁止访问生产数据库，强制开启审计日志。此层级普通用户无法修改。 User (用户级) ~/.claude/ 个人偏好 否 跨项目的通用习惯。例如：我默认开启了思维链模式，配置了个人的 GitHub Token，并安装了常用的辅助插件。 Project (项目级) 项目根目录 .claude/ 团队规范 是 团队共享的规范。例如：统一的代码格式化命令，项目专属的 MCP 服务器配置，团队共用的 Lint 规则。 Local (本地级) .claude/*.local.* 临时环境 否 (Git 忽略) 仅针对当前机器的特定配置。例如：本地数据库的连接串，临时调试用的 API Key。 配置隔离: 我始终遵循”配置隔离”原则。将涉及机密凭证的配置严格限制在 User 或 Local 作用域；将涉及工程规范的配置显式提交到 Project 作用域。 优先级与覆盖 当同一个配置项在多个作用域中同时存在时，优先级如下： Managed (最高) &gt; Command Line Flags &gt; Local &gt; Project &gt; User (最低) 这意味着： 我在命令行指定的参数（如 --model）优先级极高，适合临时测试。 我的 Local 配置可以覆盖团队的 Project 配置（例如团队要求用 Python 3.9，但我可以在本地测试 Python 3.10）。 任何配置都无法突破 Managed 层的限制。 功能模块分布 配置系统不仅管理键值对，还管理着 Agent 的扩展能力和记忆： 功能模块 用户级 (User) 项目级 (Project) 本地级 (Local) Settings (行为) ~/.claude/settings.json .claude/settings.json .claude/settings.local.json Subagents (能力) ~/.claude/agents/ .claude/agents/ — MCP Servers (连接) ~/.claude.json .mcp.json ~/.claude.json (项目状态缓存) Memory (记忆) ~/.claude/CLAUDE.md CLAUDE.md 或 .claude/CLAUDE.md CLAUDE.local.md 核心配置文件详解 Claude Code 的”大脑”由三个核心部分组成：Settings (控制中枢)、Memory (项目记忆) 和 MCP (外部连接)。 1. Settings.json：行为控制 settings.json 定义了 Claude Code 的运行规则。它不关心我的代码业务逻辑，只关心 Agent 本身如何运作。 Permissions (权限模型): 采用”最小权限原则 (Least Privilege)”。 allow: 明确放行的命令白名单。 deny: 绝对禁止的操作（如读取 .env，上传私钥）。 ask: 需要人工审批的敏感操作（默认策略）。 Sandbox (沙箱环境): 我强烈建议开启。启用后，Bash 工具将在隔离的容器化环境中运行。这不仅防止了误删系统文件，还保证了环境的一致性。 Hooks (生命周期钩子): 类似于 Git Hooks。 PreToolUse: 在工具执行前拦截，可用于强制 Lint 检查。 PostToolUse: 工具执行后触发，可用于自动化测试反馈。 示例：构建一个安全的开发环境 { \"permissions\": { \"allow\": [\"Bash(npm run *)\", \"Bash(git status)\", \"Bash(ls)\"], \"deny\": [\"Read(.env)\", \"Bash(curl -X POST *)\"], \"ask\": [\"Edit(package.json)\"] }, \"sandbox\": { \"enabled\": true, \"timeout\": 300 }, \"autoUpdater\": { \"enabled\": false } } 权限合并逻辑：权限系统的合并策略是 “收敛合并” (Restrictive Merge)。如果在 User 层允许了 curl，但在 Project 层禁止了 curl，最终结果是禁止。安全限制总是优先于许可。 2. CLAUDE.md：项目记忆 如果说 settings.json 是大脑的结构，那么 CLAUDE.md 就是大脑中的知识。它是 Claude Code 最独特的特性之一，充当了项目级系统提示词的角色。 它与传统文档的区别在于：它是写给 AI 看的，不是给通过人看的。 构建指令: 我可以明确告诉它：”在这个项目里，运行测试必须用 make test-unit，而不是 npm test。” 架构约束: 明确”负面约束”。例如：”禁止引入新的 npm 依赖，除非经过批准”、”UI 组件必须与逻辑 Hook 分离”。 风格指南: 统一代码风格，减少 Code Review 的摩擦。 3. MCP Servers：外部能力 通过 .mcp.json，Claude Code 利用 Model Context Protocol (MCP) 协议连接外部工具。它允许 Claude 连接到： GitHub/GitLab: 直接读取 Issue 内容或 PR 评论。 PostgreSQL/MySQL: 在只读权限下查询数据库 Schema，辅助编写 SQL。 Browser: 实时抓取网页文档库。 CLAUDE.md 与 Rules 文件对比 记忆文件 (CLAUDE.md) vs 规则文件 (Rules) 记忆文件 (CLAUDE.md) 性质: 项目级系统提示词 目标: 为 Claude 提供项目背景知识和上下文信息 内容: 项目规范、构建指令、架构约束、代码风格、历史配置 工作机制: 渐进式暴露动态加载，支持 @ 引用语法 使用场景: 项目初始化、需要持续记忆、需要给予项目感 规则文件 (Rules) 性质: Agent 行为控制中心 目标: 确保 Agent 操作安全可控，防止超权限或危险操作 内容: 权限模型、允许/禁止操作清单、安全策略、沙箱环境 工作机制: 层叠优先级机制，安全限制优先于允许 使用场景: 需要强制执行安全策略、需要控制权限、需要管理共享规范 核心差异对比 特征 记忆文件 (CLAUDE.md) 规则文件 (Rules) 主要用途 知识传递和上下文建立 行为控制和安全管理 内容类型 描述性、知识性 配置性、约束性 更新方式 动态热更新 静态配置更新 优先级机制 子目录优先 管理层最高 安全性要求 低 高 适用范围 项目特定 系统全局 Claude Code 中 Rules 的使用要求和规范 作用域管理 管理层 (Managed): 最高权限，企业级强制约束 用户层 (User): 个人偏好配置，不同步到 Git 项目层 (Project): 团队共享规范，同步到 Git 本地层 (Local): 机器特定配置，Git 忽略 权限模型规范 允许列表 (allow): 明确放行的操作白名单 禁止列表 (deny): 绝对禁止的高危操作 询问列表 (ask): 需要人工审批的敏感操作 安全策略要求 最小权限原则: 仅授予完成任务所必需的最小权限 收敛合并策略: 安全限制总是优先于允许 配置隔离: 敏感信息仅放在 User 或 Local 层 沙箱环境: 强烈建议启用隔离环境运行 配置优先级链 Managed (最高) &gt; 命令行参数 &gt; Local &gt; Project &gt; User (最低) 最佳实践 使用 /init 命令生成基础配置 当 Claude 出错时，立即使用 /memory 更新规则 逐步放开必要权限，同时守住安全红线 在 Project 层维护团队共享规范 在 User/Local 层管理个人偏好和敏感信息 记忆系统工作原理 Memory 机制是 Claude Code 区别于普通 Copilot 的核心。它通过结构化上下文注入，让 AI 理解项目结构。 上下文加载机制 Claude Code 通过 CLAUDE.md 文件来获取项目上下文。它不会一次性读取所有文件，而是根据我当前的工作目录 (CWD) 动态加载相关的 CLAUDE.md 文件。 加载逻辑： 定位: 确定当前 Shell 所在的路径。 回溯: 从当前路径向上查找至根目录，收集沿途所有的 CLAUDE.md。 合并: 将收集到的 Markdown 文件按”子目录优先”的顺序合并。 注入: 将合并后的文本作为 System Context 的一部分发送给模型。 场景演示： /workspace/ ├── CLAUDE.md # [Layer 1] 全局规范：Java 项目通用配置 └── services/ ├── payment-service/ │ ├── CLAUDE.md # [Layer 2] 服务规范：支付网关接口定义 │ └── src/ └── user-service/ └── CLAUDE.md # [Layer 2] 服务规范：用户数据隐私标准 当我 cd services/payment-service 后，Claude 脑子里装的是 Layer 1 + Layer 2 (Payment)。它完全不知道 User Service 的隐私标准，这完美避免了上下文污染，并节省了 Token。 动态维护 记忆不是静态的。 /init: 初始化项目记忆文件。分析 package.json 等元数据，自动生成”第一份记忆”。 /memory: 热更新记忆文件。当我在对话中纠正了 Claude 的一个错误（比如”不要用 Log4j，用 SLF4J”），我会立即使用 /memory 将这条规则写入文件。这实现了从”纠正”到”教会”的质变。 环境变量与模型调优 环境变量 (Env Vars) 环境变量不仅用于鉴权，还用于微调 Runtime 行为： ANTHROPIC_API_KEY: 必须。 BASH_DEFAULT_TIMEOUT_MS: 调整 Shell 命令的”耐心值”。对于大型编译任务，我通常会调大此值。 CLAUDE_LOG_LEVEL: 设置为 debug 可查看详细的 Prompt 交互日志，用于排查为何 Claude “不听话”。 Thinking Mode Claude 3.7+ 引入的 Thinking Mode 通过增加推理时间来提高输出质量。 原理: 模型在输出最终代码前，会进行一段内部推理，检查逻辑漏洞。 适用场景: 复杂的重构、算法设计、涉及多个文件联动的修改。 不适用场景: 简单的语法修正、文档补全（耗时且消耗 Token）。 高效协作技巧 1. 结构化需求 (Structured Prompting) 我把 Claude 当作一名高级工程师。使用 DOD (Definition of Done) 清单： “请实现用户登录功能。” (❌ 弱指令) “请实现用户登录 API，要求如下： 接口: POST /api/login，接收 JSON。 验证: 使用 Zod 进行 Schema 校验。 安全: 密码必须使用 Argon2 哈希。 测试: 编写对应的 Vitest 单元测试。 规范: 遵循 @docs/api-guide.md 中的错误码定义。” (✅ 强指令) 2. 模块化引用 (@References) CLAUDE.md 的 @ 语法支持引用文件，这实际上构建了一个知识索引。 @package.json: 告诉 Claude 当前项目的依赖版本。 @src/types.ts: 告诉 Claude 全局的数据结构定义。 善用引用，可以让 Claude 在不读取整个文件的情况下，精准获取关键上下文。 结语 配置 Claude Code 的过程，实际上就是把项目知识教给 AI 的过程。 起步: 运行 /init 生成基础配置。 调优: 发现 Claude 犯错时，立刻更新 CLAUDE.md，避免重复纠正。 定界: 通过 settings.json 管理权限。 做好配置后，每次开启新会话，Claude 都能直接理解项目背景，产出符合团队规范的代码，从而减少在”解释背景”上花费的时间。 下一篇预告：Claude Code(三)核心解密：揭秘上下文引擎与提示词系统-了解Claude Code如何管理上下文，了解如何节省token" }, { "title": "Claude Code(一)介绍与安装", "url": "/posts/claude-code-introduction/", "categories": "AI, Claude Code", "tags": "AI, CLI Agent", "date": "2026-01-10 16:21:00 +0800", "content": "Claude Code是什么 Claude Code 是 Anthropic 推出的基于 CLI（命令行界面）的下一代 AI 编程助手。不同于传统的 IDE 插件，它作为一个独立的 Agent 运行在终端中，能够直接访问本地文件系统、执行 Shell 命令、管理 Git 版本控制，并理解整个代码库的上下文结构。我从2024年9月开始一直是重症患者般地使用Cursor IDE，直到2025年12月才真正认识到CLI Agent的威力。 它不只是在帮我写代码，而是在”代理”我进行开发。我可以直接告诉它”修复这个报错”或者”重构这个模块”，它会自动分析报错信息、定位文件、修改代码、运行测试验证，直到问题解决。 flowchart TD A[用户指令] --&gt; B[分析需求并制定计划] B --&gt; C[执行相应操作] C --&gt; D[进行验证与调整] D --&gt; E[交付最终结果] C -.-&gt;|git commit| F[版本控制] C -.-&gt;|npm install| G[包管理] C -.-&gt;|pytest| H[测试执行] style A fill:#e1f5fe style E fill:#f1f8e9 Claude Code的核心能力 虽然官方文档把它描述成agentic coding tool，它不仅具有强大的编码能力，还能理解整个项目上下文、自主执行终端命令、Git操作、调用外部工具。甚至基于多模态大模型，可以干非常非常多的事，比如图片识别、生图、语音交互等等。 功能场景 具体表现 核心价值 全项目理解 能够通过 ls, grep, glob 等工具自主探索文件结构，阅读代码依赖，分析配置文件。 它的上下文不仅限于我打开的文件，而是整个工程的架构逻辑。 终端自主权 可以直接执行 Bash 命令，包括安装依赖 (npm install)、运行构建 (make build)、执行测试 (pytest)。 打通了”编写代码”到”验证代码”的闭环，拥有了执行力。 任务规划 面对复杂需求（如”重构认证模块”），能拆解为多个步骤（Plan -&gt; Act -&gt; Verify），并维护任务列表。 具备了任务拆解能力，遇到错误时会根据报错信息尝试自主修正，而不是把问题抛回给我。 版本控制集成 理解 Git 状态，能查看 git diff，分析变更，甚至帮我撰写 Commit Message 和提交代码。 将”写代码”和”提交代码”整合到了单一的对话流中，保持心流不被打断。 与Cursor的区别 Cursor 的本质依然是一个极其强大的 IDE 编辑器（Fork 自 VS Code），它的优势在于无缝的编辑器体验，通过LLM大模型极其顺滑地预测我的下一个按键，或者通过 Composer 窗口进行多文件编辑。它的核心交互依然离不开”光标”和”编辑器窗口”，就像一个坐在旁边的副驾驶。 相比之下，Claude Code 彻底抛弃了 GUI 的束缚。我不再是操作一个编辑器，而是在与一个拥有 Shell 权限的 AI 结对编程。Cursor 擅长”写”（Writing），而 Claude Code 擅长”做”（Doing）。Cursor 适合在这个文件里快速实现一个函数，而 Claude Code 适合在整个项目中从头搭建一个功能、修复一个棘手的跨文件 Bug 或进行一次大规模重构。 维度 Cursor (IDE + AI) Claude Code (CLI Agent) 核心形态 基于 VS Code 的定制编辑器 运行在终端的命令行工具 交互逻辑 补全(Tab)、聊天(Cmd+L)、内联编辑(Cmd+K) 对话式指令 (Prompt -&gt; Action -&gt; Result) 上下文范围 打开的文件、引用的代码块、向量索引 整个文件系统、终端输出、Git 历史 操作权限 主要是读写文件 读写文件 + 执行任意系统命令 适用场景 快速编码、浏览代码、即时修改 复杂重构、Debug调试、自动化脚本编写、脚手架生成 思维模式 辅助驾驶 (Copilot) 代理执行 (Agent) quadrantChart title \"AI编程工具位置对比\" x-axis \"代码编写\" --&gt; \"项目执行\" y-axis \"局部优化\" --&gt; \"全局管理\" \"Cursor\": [0.2, 0.8] \"Claude Code\": [0.8, 0.2] \"GitHub Copilot\": [0.3, 0.3] \"Tabnine\": [0.1, 0.1] 安装 官方提供了多种安装途径，但我强烈建议选择 Native Install（原生安装脚本）。相比于常见的 npm install -g，原生安装包内置了独立的运行时环境，彻底避免了因本地 Node.js 版本差异导致的各种诡异报错，且升级维护更加稳定。 # 官方推荐的安装命令（示例） curl -sL https://code.claude.com/install.sh | bash 由于众所周知的网络原因，在国内网络环境下安装或使用时，大概率会遇到连接超时或区域限制的问题。 仅仅开启系统代理软件（VPN）往往是不够的，终端（Terminal）的流量默认可能不走系统代理。我必须在 Shell 中显式 export 代理变量，否则安装和使用过程中会频发连接超时错误。 通常需要在终端显式声明代理环境变量，确保流量正确转发： # 替换为自己的代理端口，通常是 7890 或 10808 export https_proxy=http://127.0.0.1:7890 export http_proxy=http://127.0.0.1:7890 # 建议执行以下命令验证代理是否生效 curl -I https://www.google.com 模型配置 Anthropic 原生模型 (Claude 4.5 Sonnet) 这是 Claude Code 的默认且最佳体验配置。直接登录即可使用，无需复杂设置，原生支持开箱即用。 OpenAI (GPT-5.x) 虽然可以通过适配层使用 GPT-4o，但实际使用下来的感受是：模型定价较高。对于高频的 Agent 交互（通常伴随着大量的 Input Token 读取）来说，成本控制是不得不考虑的因素。 DeepSeek (V3.1) 国内之光 DeepSeek 也是很多人的首选。在配置时，通常需要指向兼容 OpenAI 格式的端点。实测下来，DeepSeek-V3 能满足日常代码分析需求，对于常见 Bug 的定位也很准确。但在处理跨多个文件的复杂逻辑或需要长上下文推理的任务时，稳定性稍逊于 Claude 4.5 Sonnet。 xAI Grok (Grok 4.1 Fast) + LiteLLM 这是一个非常有趣的非官方方案。由于 Grok 的 API 格式不兼容 Anthropic 标准，我们需要引入 LiteLLM 作为中间代理。 我现在就是用的这套方案，可以胜任95%以上的编码任务。但 LiteLLM 毕竟是代理转发工具，部分高级参数映射可能不完全。尽管如此，Grok 的推理速度和代码能力令人印象深刻。 Google Gemini 3 (Pro/Flash) + LiteLLM 理论上 Gemini 的超长上下文非常适合全库分析，但现阶段通过 LiteLLM 接入的兼容性问题较多，常出现参数校验错误。虽然 Pro 版本性能强悍且 Flash 价格诱人，但在工具链完善之前暂不推荐作为主力。可以使用Gemini CLI 直连。 其他模型 目前不推荐使用对 Tool Use（工具调用）支持不完善的模型。Claude Code 强在依赖于自家模型准确输出特定格式的工具调用指令，如果模型遵循指令能力较弱，会导致 Agent 反复尝试或卡死。 Anthropic 的风控极其严格，大陆及港澳地区 IP 直连会被立即封号，且申诉极难通过。务必确保终端流量走在靠谱的海外节点上，并保持网络环境稳定。 使用 在终端中进入项目根目录，只需输入简单的命令即可唤醒这个强大的助手： claude 首次运行时，它会花一点时间对当前目录进行索引（Indexing），建立对项目结构的大局观。这个过程非常快，且索引完全在本地构建。一旦就绪，我就进入了一个交互式的 REPL（Read-Eval-Print Loop）环境，可以像和同事聊天一样与代码库对话。 Claude Code 具有执行终端命令的权限（如 rm, git push）。虽然它在执行敏感操作前会请求批准，但在授予权限（输入 y）之前，我都会仔细阅读它打算执行的命令，避免误删文件。 工作流示范 参考官方的最佳实践，以下是两种最能体现 Claude Code 价值的经典工作流，也是我最常用的方式： 沉浸式代码探索 (Exploration) 当我接手一个遗留项目或面对复杂的开源库时，传统的做法是手动翻阅文件，试图在脑海中构建依赖关系图。而在 Claude Code 中，我可以直接提问： &gt; \"请解释一下 `auth` 模块的认证流程是如何实现的？\" &gt; \"找出所有使用了 `User` 模块的地方，并检查是否有潜在的类型安全问题。\" 它会自动运行 grep、阅读相关文件、分析引用关系，最后给出一份详尽的分析报告。这不仅是搜索，更是理解。 交互式重构与修复 (Refactoring &amp; Fixing) 这是 CLI Agent 最迷人的地方。我不再需要手动在一个个文件中复制粘贴。 &gt; \"运行测试，修复所有失败的用例。\" &gt; \"把 `src/utils` 下的大文件拆分成多个小的工具函数文件，并为它们补充单元测试。\" Claude Code 会生成一个执行计划（Plan），告诉我它准备读哪些文件、改哪些代码。在我批准后，它会像一个熟练的工程师一样，自动执行编辑、运行测试、根据报错再次修正代码，直到测试全部通过。我只需要扮演 “Tech Lead” 的角色进行 Code Review 和验收。 总结 Claude Code 的出现标志着 AI 辅助编程从”副驾驶”（Co-pilot）向”代理人”（Agent）的实质性跨越。如果说 Cursor 是让我写代码更爽的跑车，那么 Claude Code 就是能帮我自动驾驶的司机。尽管目前在模型成本和区域访问上仍有门槛，但它展示的终端自主权和全项目理解力，确实解决了很多 IDE 插件无法处理的复杂场景（如环境配置、跨模块重构）。从手动逐行编码到指挥 Agent 执行任务，我现在的角色更像是一个进行 Code Review 和技术决策的 Manager。 下一篇预告：Claude Code(二)环境配置 - 了解 Claude Code 的详细配置项" }, { "title": "Claude Code学习总结：目录导航", "url": "/posts/claude-code-guide/", "categories": "AI, Claude Code", "tags": "AI, CLI Agent", "date": "2026-01-10 15:21:00 +0800", "content": "预览 从2024年9月开始，公司内部已经开始强推Cursor IDE，今年12月中公司做AI产品的部门分享了Claude Code CLI工程实践。听完之后就开始详细了解了Claude Code是如何使用，如何利用CLI Agent提升速度与效率。经过了大约20来天断断续续的学习使用，对Claude Code有了基本认知。现在开始梳理、细化、总结这个Agent工具使用的各个部分。 系列文章目录 文章导航 简介 Claude Code #1-介绍 如何安装、设置新项目、添加上下文 Claude Code #2-初始化配置 CLAUDE.md 文件与 /init Claude Code #3-上下文窗口 理解如何管理上下文，如何节省token Claude Code #4-hooks hooks能干什么，以及如何使用钩子 Claude Code #5-斜杠命令 创建自定义斜杠命令来简化工作流程 [Claude Code #6-Agent Skills] 介绍agent技能，如何使用 [Claude Code #7-Subagents] 使用专门的字AI处理特定任务的工作流程 [Claude Code #8-Plugins] 插件的介绍、使用、开发 [Claude Code #9-MCP服务] MCP服务配置、安装、使用 [Claude Code #10-思考与技巧] 克服空白瘫痪，不断向前演进 参考来源 参考资料(截至2026年1月)： 参考信息 简介 Claude Code docs Claude Code的官方文档 包含了所有的基本用法 Claude Code Github Claude Code官方仓库 不定时发布Claude Code重要更新说明 Claude Code tutorail 知名Youtube博主的入门教程 Claude Code handbbok 非常高质量的用AI学习并总结Claude Code的博客教程 prompts-tools 获得极高star的提示词工程学习仓库 ShareAI-learn-claude-code 获得非常高star的Claude Code学习仓库 Claude-Code-Infrastructure-Showcase 获得非常高star的Claude Code学习仓库 claude-code-templates 获得非常高star的Claude Code学习仓库 SuperClaude 值得肯定的Claude Code学习仓库 awesome-claude-code 收集了学习Claude Code一揽子仓库的仓库 下一篇预告：Claude Code(一)基本接扫-了解Claude Code如何管理上下文，了解如何节省token" } ]
